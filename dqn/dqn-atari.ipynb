{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0r-iGVrY_dPh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-20T22:57:31.834210Z",
     "iopub.status.busy": "2024-01-20T22:57:31.833670Z",
     "iopub.status.idle": "2024-01-20T22:57:38.873441Z",
     "shell.execute_reply": "2024-01-20T22:57:38.872853Z",
     "shell.execute_reply.started": "2024-01-20T22:57:31.834184Z"
    },
    "executionInfo": {
     "elapsed": 18747,
     "status": "ok",
     "timestamp": 1705481744437,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "0r-iGVrY_dPh",
    "outputId": "11308d3e-2a19-4bea-c9e2-c7249b4c4475"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.29.1)\n",
      "Requirement already satisfied: wandb>0.16.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.16.2)\n",
      "Requirement already satisfied: matplotlib in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.8.2)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.16.2-cp310-cp310-macosx_10_13_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.3.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from gymnasium->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from gymnasium->-r requirements.txt (line 1)) (1.26.3)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from gymnasium->-r requirements.txt (line 1)) (0.0.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from gymnasium->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: shimmy[atari]<1.0,>=0.1.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from gymnasium->-r requirements.txt (line 1)) (0.2.1)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from gymnasium->-r requirements.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from wandb>0.16.0->-r requirements.txt (line 4)) (3.1.41)\n",
      "Requirement already satisfied: setproctitle in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from wandb>0.16.0->-r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from wandb>0.16.0->-r requirements.txt (line 4)) (8.1.7)\n",
      "Requirement already satisfied: PyYAML in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from wandb>0.16.0->-r requirements.txt (line 4)) (6.0.1)\n",
      "Requirement already satisfied: setuptools in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from wandb>0.16.0->-r requirements.txt (line 4)) (63.2.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from wandb>0.16.0->-r requirements.txt (line 4)) (5.9.8)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from wandb>0.16.0->-r requirements.txt (line 4)) (1.39.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from wandb>0.16.0->-r requirements.txt (line 4)) (2.31.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from wandb>0.16.0->-r requirements.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from wandb>0.16.0->-r requirements.txt (line 4)) (4.25.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from wandb>0.16.0->-r requirements.txt (line 4)) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (3.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (23.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (4.47.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: torch==2.1.2 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from torchvision->-r requirements.txt (line 6)) (2.1.2)\n",
      "Requirement already satisfied: jinja2 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from torch==2.1.2->torchvision->-r requirements.txt (line 6)) (3.1.3)\n",
      "Requirement already satisfied: sympy in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from torch==2.1.2->torchvision->-r requirements.txt (line 6)) (1.12)\n",
      "Requirement already satisfied: filelock in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from torch==2.1.2->torchvision->-r requirements.txt (line 6)) (3.13.1)\n",
      "Requirement already satisfied: networkx in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from torch==2.1.2->torchvision->-r requirements.txt (line 6)) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from torch==2.1.2->torchvision->-r requirements.txt (line 6)) (2023.12.2)\n",
      "Requirement already satisfied: tqdm in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium->-r requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium->-r requirements.txt (line 1)) (0.6.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb>0.16.0->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>0.16.0->-r requirements.txt (line 4)) (4.0.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb>0.16.0->-r requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb>0.16.0->-r requirements.txt (line 4)) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb>0.16.0->-r requirements.txt (line 4)) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb>0.16.0->-r requirements.txt (line 4)) (3.6)\n",
      "Requirement already satisfied: ale-py~=0.8.1 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from shimmy[atari]<1.0,>=0.1.0->gymnasium->-r requirements.txt (line 1)) (0.8.1)\n",
      "Requirement already satisfied: importlib-resources in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0->gymnasium->-r requirements.txt (line 1)) (6.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>0.16.0->-r requirements.txt (line 4)) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from jinja2->torch==2.1.2->torchvision->-r requirements.txt (line 6)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/garethdavies/Development/workspaces/rl/venv/lib/python3.10/site-packages (from sympy->torch==2.1.2->torchvision->-r requirements.txt (line 6)) (1.3.0)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.16.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "376173c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T22:59:54.192280Z",
     "iopub.status.busy": "2024-01-20T22:59:54.191648Z",
     "iopub.status.idle": "2024-01-20T22:59:55.832656Z",
     "shell.execute_reply": "2024-01-20T22:59:55.831969Z",
     "shell.execute_reply.started": "2024-01-20T22:59:54.192253Z"
    },
    "executionInfo": {
     "elapsed": 10879,
     "status": "ok",
     "timestamp": 1705481763504,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "376173c5"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1b7b7fde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T22:59:55.833970Z",
     "iopub.status.busy": "2024-01-20T22:59:55.833681Z",
     "iopub.status.idle": "2024-01-20T22:59:56.225954Z",
     "shell.execute_reply": "2024-01-20T22:59:56.225203Z",
     "shell.execute_reply.started": "2024-01-20T22:59:55.833950Z"
    }
   },
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a0ae1f72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:00:20.539985Z",
     "iopub.status.busy": "2024-01-20T23:00:20.539550Z",
     "iopub.status.idle": "2024-01-20T23:00:20.546774Z",
     "shell.execute_reply": "2024-01-20T23:00:20.545766Z",
     "shell.execute_reply.started": "2024-01-20T23:00:20.539936Z"
    },
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1705481771579,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "a0ae1f72"
   },
   "outputs": [],
   "source": [
    "environment = \"ALE/Breakout-v5\"\n",
    "bs = 32\n",
    "replay_memory_size= 1_000_000 #replay memory max size\n",
    "sync_every_n_steps = 10_000\n",
    "gamma = 0.99\n",
    "lr=0.00025\n",
    "epsilon = 1\n",
    "final_epsilon = 0.1,\n",
    "loss_fn = nn.SmoothL1Loss()\n",
    "Optimizer = torch.optim.Adam\n",
    "replay_start_size = 50_000\n",
    "FRAMES_TO_TRAIN = 10_000_000\n",
    "EPOCH_SIZE = 50_000\n",
    "BASE_MODEL = None\n",
    "final_exploration_frame = 1_000_000\n",
    "MIN_STACK_SIZE = 4\n",
    "max_grad_norm = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7888d948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:00:32.006597Z",
     "iopub.status.busy": "2024-01-20T23:00:32.006068Z",
     "iopub.status.idle": "2024-01-20T23:00:32.011303Z",
     "shell.execute_reply": "2024-01-20T23:00:32.010506Z",
     "shell.execute_reply.started": "2024-01-20T23:00:32.006563Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": lr,\n",
    "    \"architecture\": \"DQN-Deepmind-2015\",\n",
    "    \"environment\": environment,\n",
    "    \"epsilon\": epsilon,\n",
    "    \"final_epsilon\": final_epsilon,\n",
    "    \"gamma\":gamma,\n",
    "    \"bs\":bs,\n",
    "    \"replay_memory_size\":replay_memory_size,\n",
    "    \"sync_every_n_steps\": sync_every_n_steps,\n",
    "    \"loss\": str(loss_fn),\n",
    "    \"Optimizer\": Optimizer.__name__,\n",
    "    \"frames_to_train\": FRAMES_TO_TRAIN,\n",
    "    \"epoch_size\":EPOCH_SIZE,\n",
    "    \"base_model\": BASE_MODEL,\n",
    "    \"final_exploration_frame\":final_exploration_frame,\n",
    "    \"replay_start_size\":replay_start_size,\n",
    "    \"max_grad_norm\":10\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc4ad55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:00:55.330097Z",
     "iopub.status.busy": "2024-01-20T23:00:55.329165Z",
     "iopub.status.idle": "2024-01-20T23:00:59.771287Z",
     "shell.execute_reply": "2024-01-20T23:00:59.770703Z",
     "shell.execute_reply.started": "2024-01-20T23:00:55.330065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ft4pmrub) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a397cd3349a4595ba518990878edfd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.008 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peachy-shadow-17</strong> at: <a href='https://wandb.ai/garethmd/atari/runs/ft4pmrub' target=\"_blank\">https://wandb.ai/garethmd/atari/runs/ft4pmrub</a><br/> View job at <a href='https://wandb.ai/garethmd/atari/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMTkzNjA0NQ==/version_details/v1' target=\"_blank\">https://wandb.ai/garethmd/atari/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMTkzNjA0NQ==/version_details/v1</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240120_230052-ft4pmrub/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ft4pmrub). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1560c095b2c64064a6c0350564e4322c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113193878231363, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240120_230055-gswyd628</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/garethmd/atari/runs/gswyd628' target=\"_blank\">quiet-snow-18</a></strong> to <a href='https://wandb.ai/garethmd/atari' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/garethmd/atari' target=\"_blank\">https://wandb.ai/garethmd/atari</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/garethmd/atari/runs/gswyd628' target=\"_blank\">https://wandb.ai/garethmd/atari/runs/gswyd628</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/garethmd/atari/runs/gswyd628?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f5e7a616f70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"atari\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a4f900d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2024-01-20T23:00:59.772864Z",
     "iopub.status.busy": "2024-01-20T23:00:59.772691Z",
     "iopub.status.idle": "2024-01-20T23:00:59.794620Z",
     "shell.execute_reply": "2024-01-20T23:00:59.794002Z",
     "shell.execute_reply.started": "2024-01-20T23:00:59.772844Z"
    },
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1705481765159,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "a4f900d0",
    "outputId": "dd9ec3fb-d6b1-4751-f00f-7ee107ee89fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2ae8f22d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:01:02.943475Z",
     "iopub.status.busy": "2024-01-20T23:01:02.943188Z",
     "iopub.status.idle": "2024-01-20T23:01:03.084200Z",
     "shell.execute_reply": "2024-01-20T23:01:03.083484Z",
     "shell.execute_reply.started": "2024-01-20T23:01:02.943453Z"
    },
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1705481767156,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "2ae8f22d"
   },
   "outputs": [],
   "source": [
    "class TorchEnv:\n",
    "    def __init__(self, env: gym.Env, transforms=None):\n",
    "        self.env = env\n",
    "        self.n_observations = self.env.observation_space.shape[0]\n",
    "        self.n_actions = self.env.action_space.n\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def step(self, a):\n",
    "        s, r, terminated, _, info = self.env.step(a)\n",
    "        if self.lives != info['lives']:\n",
    "            terminated = True\n",
    "        \n",
    "        if self.transforms:\n",
    "            s = s[None, :, :, :] # HWC -> BCHW\n",
    "            s = self.transforms(s)\n",
    "        return s, r, terminated\n",
    "\n",
    "    def reset(self, *args, **kwargs):\n",
    "        terminated = False\n",
    "        s, info = self.env.reset(*args, **kwargs)\n",
    "        self.lives = info['lives']\n",
    "    \n",
    "        stack = [s]\n",
    "        while terminated == False and len(stack)<MIN_STACK_SIZE:\n",
    "            a = np.random.randint(self.n_actions)\n",
    "            s_prime, r, terminated, *_ = self.env.step(a)\n",
    "            stack.append(s_prime)\n",
    "        stack = np.stack(stack, axis=0)\n",
    "\n",
    "        if self.transforms:\n",
    "            stack = self.transforms(stack)\n",
    "        \n",
    "        return stack\n",
    "\n",
    "    def close(self):\n",
    "        return self.env.close()\n",
    "    \n",
    "    def sample(self):\n",
    "        return np.random.randint(self.n_actions)\n",
    "\n",
    "env = TorchEnv(gym.make(environment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8c94d865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.test_step_should_be_correct_dtype()>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_stack_should_be_correct_shape():\n",
    "    env = TorchEnv(gym.make(environment))\n",
    "    stack = env.reset()\n",
    "    assert stack.shape == (4, 210, 160, 3) # 4 frames, 210x160, 3 channels\n",
    "\n",
    "def test_stack_should_be_correct_dtype():\n",
    "    env = TorchEnv(gym.make(environment))\n",
    "    stack = env.reset()\n",
    "    assert stack.dtype == np.uint8\n",
    "\n",
    "def test_step_should_be_correct_dtype():\n",
    "    env = TorchEnv(gym.make(environment))\n",
    "    _ = env.reset()\n",
    "    stack, r, terminated = env.step(0)\n",
    "    assert stack.dtype == np.uint8\n",
    "\n",
    "\n",
    "\n",
    "test_stack_should_be_correct_shape()\n",
    "test_stack_should_be_correct_dtype()\n",
    "test_step_should_be_correct_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83317d5b",
   "metadata": {
    "id": "83317d5b"
   },
   "source": [
    "## Breakout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7d9f1",
   "metadata": {
    "id": "b3b7d9f1"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "23fe59a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x131bf2620>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = TorchEnv(gym.make(environment))\n",
    "stack = env.reset() \n",
    "plt.imshow(stack[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d079db6b",
   "metadata": {},
   "source": [
    "#### Greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "044326eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:01:10.193326Z",
     "iopub.status.busy": "2024-01-20T23:01:10.192530Z",
     "iopub.status.idle": "2024-01-20T23:01:10.196101Z",
     "shell.execute_reply": "2024-01-20T23:01:10.195675Z",
     "shell.execute_reply.started": "2024-01-20T23:01:10.193304Z"
    },
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1705481777407,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "044326eb"
   },
   "outputs": [],
   "source": [
    "greyscale = transforms.Grayscale() #transforms to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c01eb3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGrayscale:\n",
    "    def __init__(self):\n",
    "        self.transforms = transforms.Grayscale()\n",
    "\n",
    "    def __call__(self, batch: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch (torch.Tensor): expects batch to be of shape (B, H, W, C)\n",
    "        Returns:\n",
    "            torch.Tensor: batch of shape (B, C, H, W)\n",
    "        \"\"\"\n",
    "        grey_pt_stack = torch.stack([self.transforms(s.permute(2,0,1)) for s in batch])\n",
    "        return grey_pt_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f194f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imglistshow(v_slice):\n",
    "    plt.figure()\n",
    "    #subplot(r,c) provide the no. of rows and columns\n",
    "    f, axarr = plt.subplots(1,4) \n",
    "\n",
    "    # use the created array to output your multiple images. In this case I have stacked 4 images vertically\n",
    "    axarr[0].imshow(v_slice[0])\n",
    "    axarr[1].imshow(v_slice[1])\n",
    "    axarr[2].imshow(v_slice[2])\n",
    "    axarr[3].imshow(v_slice[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "152a968b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAC+CAYAAAAfrfTyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh3klEQVR4nO3dfXRU9b3v8ffMJJmkQCYEkgyRRCJqAQXk8BBisUVJCbRSH3CdyqIWPSy5x0s4V1OPLR4rR6XGqld7QJS72l7RXhGrrXqbVrwISqqGgBFLBXmSKOFhEiAmkwTyOPv+kTIwkkAmmcneM/N5rTVrOXv/svd3Jh9/fLP3nj02wzAMRERERCzEbnYBIiIiIl+nBkVEREQsRw2KiIiIWI4aFBEREbEcNSgiIiJiOWpQRERExHLUoIiIiIjlqEERERERy1GDIiIiIpajBkVEREQsx9QGZdWqVYwYMYLExERyc3PZunWrmeWICZQBUQYElAM5l2kNyiuvvEJRURHLli3j448/Zvz48RQUFFBTU2NWSdLPlAFRBgSUA+mazawvC8zNzWXy5Mk888wzAPh8PrKysliyZAk/+9nPzChJ+pkyIMqAgHIgXYszY6etra1UVFSwdOlS/zK73U5+fj5lZWXnjG9paaGlpcX/3OfzUVtby5AhQ7DZbP1Ss/SeYRg0NDSQmZmJ3d550E4ZiC2hyAAoB5FOc4F0lYHumNKgHD9+nI6ODjIyMgKWZ2RksHv37nPGFxcX89BDD/VXeRImVVVVDB8+HFAGYlVfMgDKQbTQXCBnZ6A7pjQowVq6dClFRUX+5/X19WRnZzON7xFHvImVSU+008b7/IVBgwb1ehvKQGQLRQZAOYh0mgskmAyY0qAMHToUh8NBdXV1wPLq6mrcbvc5451OJ06n85zlccQTZwtPIKv+42pax5zqdv1FL8eTWLIVbDb2rpqMw9XW7djLH/LSsfdzHBnp7PmfF9HdUciOFgej/vun+Jqbg6q17rY8Tszq/mcGfZBE+rMfBrXNszlGX8beBwYCMPQvTlwvbQluA/+4yunsw6/KQNfjlIHuMwDKwYXEQg6UgfOLxAx0x5QGJSEhgYkTJ7Jx40ZuvPFGoPM84saNGyksLDSjpHMMvsbDy2NepM2AJQf+mTafg9EuD/emvwvA9RX3MewfY5dd9wbXfeMAB9qS+cUX3wdgdsZObkneAcDC9ELse4HkgbxzzUocNtjQdCnrjkwGYHH2u/yT08OR9iQeip8OQQaydixsumYlAPcfup7qU4Gd6RFXVu/ehH9ozRjEpmtWAJBf9e+4+rS1TsqAMhAJGQDl4GyxmgNl4IxwZKA7pn3MuKioiF//+te88MILfPbZZ9x11100NTVxxx13mFVSl451JGH8oAH7jCq2PTXxvGNfOp6HfUYV9hlVPPeXgvOOXV52vX/sE5/PDFm91UtzsH/3SMBj+GNdX3BoNmVAGYiUDIByEE6RkgNloH+Zdg3KD3/4Q44dO8aDDz6Ix+PhqquuYv369edcKCXBWfKbVzjpCzz8ef/b/8xl/1ZuUkXdUwbCQxkQUA4ksjLQFVMvki0sLLTMIbxIlvVOG7Pr7gtY1uoy2DjvCQCMgR1mlNUjykBoKAMCyoFEdga+LiI+xWOmeFsHp64ZhaPZR/3I858Ry0ys48B1UwHocLecd2zKkEbar+s8RHjRwC/6VGPS/uO424cELDuZEU/HreDQbQH6TBkQUA5EGehvalAuIM3Ryourn+7R2IWDy1m4pmeHzt6c8BtYE7isg96lZ++/DmPjrU/06mflwpQBAeVAlIH+Ztqt7vvC6/XicrmYzg1h+1hZXM7F+AYldbvedriGjhO1QOfHrox4R/cb2/sFvuZmbHFx2MZc2v02Oww6du2FIH8lce4MfOmDu11vr22g/dDhoLYZ8POJiXD5iM4aq2vpqA7u+zHajTbe403q6+tJTk7udR1nUwa+VmsMZgCUg3NqjcEcKANfqzWKMhDRR1Aql0/pfLNM0X0A+jZ2arCF9HD/2SHc1sigfsLX3AwPvBmi/QdSBoLZf3RmAJSD4PYfnTlQBoLZf2RkIKKPoOzYlc6gQaZ9Ulp6qKHBx7gxNWH5q0kZiAzhyAAoB5FGc4EEkwH9NkVERMRy1KCIiIiI5ahBEREREctRgyIiIiKWowZFRERELEcNioiIiFiOGhQRERGxHDUoIiIiYjkRfSfZr7v/0PVs/fJis8uIaVMu/pJHh5eYtn9lwHxmZwCUAyswOwfKgPn6moGoalB2vDaGnKc+NLuMmPa3e6+GfzNvUlIGzGd2BkA5sAKzc6AMmK+vGdApHhEREbEcNSgiIiJiOWpQRERExHLUoIiIiIjlqEERERERy1GDIiIiIpajBkVEREQsRw2KiIiIWE7IG5T//M//xGazBTxGjRrlX9/c3MzixYsZMmQIAwcOZO7cuVRXV4e6DDHRr55qICfL43+MG1MTsF4ZiA1n5+B0BiZNmuRfrxxEP80F0hdhOYJyxRVXcPToUf/j/fff96+75557+NOf/sSrr77K5s2bOXLkCDfffHM4yhATXX55HFsr0thakcamzUMC1ikDseN0Dk5n4O233/avUw5ig+YC6a2w3Oo+Li4Ot9t9zvL6+np++9vfsnbtWq677joAnn/+eUaPHs2WLVuYOnVqOMoREzjiIC3dAUBiks2/XBmILadzcDoDQ4Z0/gOlHMQOzQXSW2FpUPbt20dmZiaJiYnk5eVRXFxMdnY2FRUVtLW1kZ+f7x87atQosrOzKSsr6zaQLS0ttLS0+J97vd5wlC0h9EVlB7kTa3Am2hg79kzMlIHYcjoH8Qmdz6uqqrjiiiuUgxiiuUB6K+SneHJzc1mzZg3r16/nueeeo7KykmuuuYaGhgY8Hg8JCQmkpKQE/ExGRgYej6fbbRYXF+NyufyPrKysUJctIXTVhASeeMrFmv8zmEd+kczhwx0AykCMOTsHDzw4CIDZs2crBzFEc4H0RciPoMyePdv/3+PGjSM3N5eLL76Y3//+9yQlJfVqm0uXLqWoqMj/3Ov1KpQWNv1ap/+/R4+GSy9zMG3qcV5//XVSU1N7tU1lIPKcnYPhwzsP8dfX12suiCGaC6QvwnKK52wpKSlcfvnl7N+/n+9+97u0trZSV1cX0DVXV1d3ec3KaU6nE6fT2e16sbbk5M4DdQcOHGDMmDHKQAwbOXKk5oIYprlAghH2BqWxsZHPP/+c2267jYkTJxIfH8/GjRuZO3cuAHv27OHgwYPk5eX1eV9N/3SKY3f1fTvSe6cmnDpn2ckmHwBut1sZiAFdZeC0yspKhg0bphzEAM0Fcr65oCdC3qDce++9zJkzh4svvpgjR46wbNkyHA4H8+bNw+VysXDhQoqKikhNTSU5OZklS5aQl5cXkiu2F1+1mY8vyQ7Bq5DemuT6gl884mVGfiLDh9uprvbx5OMNANxyyy3KQAyY5PoCICAHlZWd1x5oLogdmgvk9FzQWyFvUA4dOsS8efM4ceIEaWlpTJs2jS1btpCWlgbA008/jd1uZ+7cubS0tFBQUMCzzz4b6jLERJ6jPv5HYR11dT5SU+1cNSEegKFDhwLKQKw4OwcpgzsP7b/zzjuaC2KI5gLpC5thGIbZRQTL6/XicrnYsSudQYPOfBDpNe84PvaqYzbTJNcX3Dzo04BlDQ0+xo2pob6+nuTk5JDsRxmwrv7KACgHVqa5QPqagbBfg9KfhsZ5yU6qNbuMmJYW12Dq/pUB85mdAVAOrMDsHCgD5utrBqKqQRmRcJwB9lazy4hpaXHm3jRJGTCf2RkA5cAKzM6BMmC+vmZA32YsIiIilqMGRURERCxHDYqIiIhYTlRdg+LAh8PmM7uMmObA3PdfGTCf2Rk4XYNyYC6zc6AMmK+vGdARFBEREbEcNSgiIiJiOVF1imeQvRUH9WaXEdO+YW8zdf/KgPnMzgAoB1Zgdg6UAfP1NQNR1aBcGmfnG3aH2WXEtJO+Do6beNpXGTCf2RkA5cAKzM6BMmC+vmZAp3hERETEctSgiIiIiOVE1Smeel8rjYb5579jWYfJ3z2pDJjP7AyAcmAFZudAGTBfXzMQVQ3KtpZ0DrSmm11GTLskoYarnDWm7V8ZMJ/ZGQDlwArMzoEyYL6+ZkCneERERMRy1KCIiIiI5UTVKZ7ajoFUNaeaXUZMS3GcBMw7rKsMmM/sDIByYAVm50AZMF9fMxBVDcob1RP424HhZpcR0ypHDuG6EQdM278yYD6zMwDKgRWYnQNlwHx9zYBO8YiIiIjlqEERERERy4mqUzzHTw3A/lW82WXEtOOnBpq8f2XAbGZnoLMG5cBsZudAGTBfXzMQVQ2K9/+5ufSpD80uI6YdufdqGG3e/pUB85mdAVAOrMDsHCgD5utrBoI+xVNaWsqcOXPIzMzEZrPxxhtvBKw3DIMHH3yQYcOGkZSURH5+Pvv27QsYU1tby/z580lOTiYlJYWFCxfS2NjY+1ch/eor4xifGB9QapTwjvEaNcbhgPWGYfDUkw1MmVjDqEs93PkvX52zDWUgsikDAsqBhFfQDUpTUxPjx49n1apVXa5//PHHWbFiBatXr6a8vJwBAwZQUFBAc3Ozf8z8+fPZuXMnGzZsoKSkhNLSUhYtWtT7VyH9qoN2BuJiFBO6XP+/nmtizfMnWf5oMq//aQhJSTYAZSCKKAMCyoGEV9ANyuzZs1m+fDk33XTTOesMw+BXv/oVDzzwADfccAPjxo3jxRdf5MiRI/4jLZ999hnr16/nN7/5Dbm5uUybNo2VK1eybt06jhw50ucXJOE31DaMS21Xkm676Jx1hmHwv397ksIlA5lZkMjo0fH84rFkAEpKSgBlIBooAwLKgYRXSD/FU1lZicfjIT8/37/M5XKRm5tLWVkZAGVlZaSkpDBp0iT/mPz8fOx2O+Xl5V1ut6WlBa/XG/AQa2qrr+VYjY9p1yT4lw0a1Bmzbdu2AcpAtAtXBkA5iCSaC6SvQtqgeDweADIyMgKWZ2Rk+Nd5PB7S0wO/wCkuLo7U1FT/mK8rLi7G5XL5H1lZWaEsW0Kovalzshg69NxoVVdXA8pAtAtXBkA5iCSaC6SvIuI+KEuXLqW+vt7/qKqqMrsk6WfKgIByIMpALAnpx4zdbjfQ2R0PGzbMv7y6upqrrrrKP6amJvDe/O3t7dTW1vp//uucTidOpzOUpUqYxA3oPMd8/LiP9AxHwLrTR9aUgegWrgyAchBJNBdIX4X0CEpOTg5ut5uNGzf6l3m9XsrLy8nLywMgLy+Puro6Kioq/GM2bdqEz+cjNzc3lOWICeJdqaSl2/ng/Vb/ssZGHwCTJ08GlIFopwwIKAfSd0EfQWlsbGT//v3+55WVlXzyySekpqaSnZ3N3XffzfLly7nsssvIycnh5z//OZmZmdx4440AjB49mlmzZnHnnXeyevVq2traKCws5NZbbyUzMzNkL0zCp91o5xRn7lNwiiYajDriScBms/EvC7/BMysbGZHjICvLweOPNQBw/fXXA8pANFAGBJQDCa+gG5SPPvqIa6+91v+8qKgIgAULFrBmzRruu+8+mpqaWLRoEXV1dUybNo3169eTmJjo/5mXXnqJwsJCZsyYgd1uZ+7cuaxYsSIEL0f6g5daPqbU/3wfOwAYxsUMJp//dtcATp40uP9nXrxeHxMmdN5uWhmIHsqAgHIg4RV0gzJ9+nQMw+h2vc1m4+GHH+bhhx/udkxqaipr164NdtdiEam2dPK5pct1R+jMQNG9gyi6dxAADQ0+xo0JPM+sDEQ2ZUBAOZDwiohP8YiIiEhsUYMiIiIilqMGRURERCxHDYqIiIhYjhoUERERsRw1KCIiImI5alBERETEctSgiIiIiOWoQRERERHLUYNiMvu4URxflAd2x4UHi4iIxAg1KCaruyKF1B8ewhYf9LcOiIiIRC01KCIiImI5alBMNnjTARw/dWG0tppdivQjx5BU9q2ZiG3SlWaXIiJiSTqvYLKO6hqorrnwQIkqtvh4plxWybHkHP1PKCLSBR1BETGBYRh86R2MvbXD7FLEBI4hqdgHDTK7DBFL0x9vIiboqK4h+fsnwKcGJRbtfmoESXsSGf7oh2aXImJZOoIiYhY1JzHLZjcwbGZXIWJtalBERPrZwI+SGLxXDWqssV85iubrp5hdRsTQKR4RkX7m/i+d2olFnump+PK/wl1idiWRQUdQRERExHJ0BEVERKQfDNt0nFP7XWaXETHUoIiIiPSDjl17SdhldhWRQ6d4RERExHKCblBKS0uZM2cOmZmZ2Gw23njjjYD1t99+OzabLeAxa9asgDG1tbXMnz+f5ORkUlJSWLhwIY2NjX16IdJ/vjKO8YnxAaVGCe8Yr1FjHA5Yf+89deRkefyPcWPOvVOuMhDZlAEB5UDCK+gGpampifHjx7Nq1apux8yaNYujR4/6Hy+//HLA+vnz57Nz5042bNhASUkJpaWlLFq0KPjqxRQdtDMQF6OY0O2Y70xPYGtFGlsr0ti0ecg565WByKYMCCgHEl5BX4Mye/ZsZs+efd4xTqcTt9vd5brPPvuM9evXs23bNiZNmgTAypUr+d73vseTTz5JZmZmsCVJPxtqG8ZQhnU+Mboek5BgIy3dAUBiUuAdqZSByKcMCCgHEl5huUj2vffeIz09ncGDB3PdddexfPlyhgzp7JzLyspISUnxhxEgPz8fu91OeXk5N9100znba2lpoaWlxf/c6/WGo2wJoS1bWpl0VQ3JLhuTJicErFMGYkOoMwDKQSTSXCC9FfIGZdasWdx8883k5OTw+eefc//99zN79mzKyspwOBx4PB7S09MDi4iLIzU1FY/H0+U2i4uLeeihh0JdqoTJd6Y7KZidSFaWg4NfdvDL4gYAOjo675ypDES/cGQAlINIo7lA+iLkn+K59dZb+cEPfsDYsWO58cYbKSkpYdu2bbz33nu93ubSpUupr6/3P6qqqkJXsITcnBuS+O7MREaNjmfmrESeeS4FgL/+9a+93qYyEFnCkQFQDiKN5gLpi7DfB+WSSy5h6NCh7N+/nxkzZuB2u6mpCbySu729ndra2m6vW3E6nTidznCXKmEyPKvz/POBAwcAlIEYFIoMgHIQ6TQXSDDCfh+UQ4cOceLECYYN67yQKi8vj7q6OioqKvxjNm3ahM/nIzc3N9zliAk8ns7DuacnHGUg9igDAsqBBCfoIyiNjY3s37/f/7yyspJPPvmE1NRUUlNTeeihh5g7dy5ut5vPP/+c++67j0svvZSCggIARo8ezaxZs7jzzjtZvXo1bW1tFBYWcuutt+qK7QjRbrRzijP3KThFEw1GHfEk4Gtt4dHlXmZ/L5G0NDtfftnBLx7pPO88Y8YMQBmIBsqAgHIg4RV0g/LRRx9x7bXX+p8XFRUBsGDBAp577jl27NjBCy+8QF1dHZmZmcycOZNHHnkk4JDcSy+9RGFhITNmzMButzN37lxWrFgRgpcj/cFLLR9T6n++jx0ADONiXLZvs/uzdv74Wh1er4/0DDtT8xL4bFe7MhBFlAEB5UDCK+gGZfr06RhGNx94B95+++0LbiM1NZW1a9cGu2uxiFRbOvnc0uW6I/EJvPhSasCyhgYff3i1OXAbykBEUwYElAMJL30Xj4iIiFiOGhQRERGxHDUoIiIiYjlqUERERMRy1KCIiIiI5ahBEREREctRgyIiIiKWowZFRERELEcNioiIiFiOGhQRERGxHDUoIiIiYjlqUERERMRy1KCIiIiI5ahBEREREctRgyIiIiKWowZFRERELEcNioiIiFiOGhQRERGxnDizC+iLkz47dt+ZHsvmM7EYk9gTEzGuGNmjsY4TDbR/cTC89bTBkfakgGVN7eH7xSgDygAoBz1hi4uDsd/s0Z+ldu8pOvYd6NP+NBdEn7is4XSku3o01rb3YJ8zENENysctw0mKP/MSHM2GidWY5NIRDF15uEdDt707mhH/Ed5/nBK/MnjGMyNgWVtTK/BiWPanDBDzGQDloCccQ4cw6JmjxPXgX+4PdlzO5f/atwZFc0H0+eJH2UyYs6tHY2v+fWSfM6BTPCIiImI5EX0ERcB2rJa//35Mj8YO29sW5mrEDMqA9ISvoZHPfj8ebBcem3lE50fkXO6tLfz9VM/mmuGHqmDk8D7tTw1KhOuorsH9qxqzy/CLb/Lxt+rMgGUdJ1tMqiY2KAPSE76mJtz/9WG/7U85iD5xGytwb+zZ2HYgvimzTxkIqkEpLi7mj3/8I7t37yYpKYmrr76aX/7yl3zzm9/0j2lubuYnP/kJ69ato6WlhYKCAp599lkyMjL8Yw4ePMhdd93Fu+++y8CBA1mwYAHFxcXExQXXLz35+k3YExP9z7M/PRXUz0vvVBq7OcZhmmjAjoMUhnApYxlgG8SAP5Qz4A/QYXSwjx1UU0UHHQDU1NSQnJzs304ocqAMmMNKGQDlwAznywDAgD+Uk/jamQz46GAw6edsRxmIXqfngrO1G23s6eHPB5WAzZs3s3jxYiZPnkx7ezv3338/M2fOZNeuXQwYMACAe+65hz//+c+8+uqruFwuCgsLufnmm/nggw8A6Ojo4Pvf/z5ut5sPP/yQo0eP8uMf/5j4+HgeffTRYMohe/lW4mzxQf2M9F0dxxjOSJIZjIHBfj5lO38lz5iJw9YZqb38jeMcZSxTsWGjgs386Ec/YsuWLUDocqAMmMNKGQDlwAzBZiCOeHbzccA2lAE5H5thGL2+1PnYsWOkp6ezefNmvv3tb1NfX09aWhpr167llltuAWD37t2MHj2asrIypk6dyltvvcX111/PkSNH/EdVVq9ezU9/+lOOHTtGQkLCBffr9XpxuVxM5wYF0gJajRZK+RMT+Q6DbWm0G21s5v9yJblk2IbTbrTxHm8ChCwHyoC1mJEBUA6s5EIZAKg3atnGJt555x1mzJihDMSg03NBfX19wNHUrvTpUzz19fUApKamAlBRUUFbWxv5+fn+MaNGjSI7O5uysjKgc3IaO3ZswCmfgoICvF4vO3fu7HI/LS0teL3egIdYRzudF17G0zmZePkKA4PUrx3OzcrK6nUOlAFr648MgHJgZT3JwAA6T/9s3boVUAbk/HrdoPh8Pu6++26+9a1vceWVVwLg8XhISEggJSUlYGxGRgYej8c/5uwwnl5/el1XiouLcblc/kdWVlZvy5YQMwyDvXyCiyEMtHXewKeVZmzYibcF/vWTlpbW6xwoA9bVXxkA5cCqgskAQHV1NaAMyPn1ukFZvHgxn376KevWrQtlPV1aunQp9fX1/kdVVVXY9yk9s5vtNOJlLLlh3Y8yYF39lQFQDqxKGZBw6NXHjAsLCykpKaG0tJThw898ztntdtPa2kpdXV3AUZTq6mrcbrd/zOnDe2evP72uK06nE6fT2ZtSJYx2G9s5zlEmMZ1E2zf8yxNIxMBHm9Ea8NfTsWPHep0DZcCa+jMDoBxYUbAZgDNHSZQBOZ+gjqAYhkFhYSGvv/46mzZtIicnJ2D9xIkTiY+PZ+PGMx+U3rNnDwcPHiQvLw+AvLw8/v73v1NTc+a+DRs2bCA5OZkxY3p2Axgxl2EY7Da2c4zDTOTbJNkGBKxPZjA2bNQSeG+Oqqoq5SBKKAPSmwycpAGAKVOmAMqAnF9QR1AWL17M2rVrefPNNxk0aJD/HKHL5SIpKQmXy8XChQspKioiNTWV5ORklixZQl5eHlOnTgVg5syZjBkzhttuu43HH38cj8fDAw88wOLFi9UVR4g9bMdDFeO5GgfxtBjNAMQRj8PmIM4WT6aRwz52EG8kYPvHrSunTJmiHEQJZUCCzUDnx4y3AzB58mRAGZDzC6pBee655wCYPn16wPLnn3+e22+/HYCnn34au93O3LlzA27UdprD4aCkpIS77rqLvLw8BgwYwIIFC3j44Yd7XMfpT0a30wb6Pqh+d4jOLxGrYHPA8m8ygWFGNgCXMAYDHzsow0fnbbN/97vf+cf2NQfKgLmskAFQDszUmwwMZihw5vemDMSe05/26skdTvp0HxSzHDhwgJEje/b18mIdVVVVAdcs9cWhQ4d09X4ECmUGQHNBpNJcID3JQEQ2KHV1dQwePJiDBw/icrnMLsd0Xq+XrKwsqqqqLnjjGzMYhkFDQwOZmZnY7aH5Am2fz8eePXsYM2aMZV93f4rFDIDmgq+LxRxoLggUTRmIyC8LPP2iXC6XJX8BZklOTrbs+xHqfzzsdjsXXXQRYO3X3d+s/F6Eo4HQXNC1WMqB5oKuWfm96GkGQvenjIiIiEiIqEERERERy4nIBsXpdLJs2TJ9DO0fYvX9iNXX3ZVYfS9i9XV3J1bfj1h93V2JpvciIi+SFRERkegWkUdQREREJLqpQRERERHLUYMiIiIilqMGRURERCwnIhuUVatWMWLECBITE8nNzT3n67qjQWlpKXPmzCEzMxObzcYbb7wRsN4wDB588EGGDRtGUlIS+fn57Nu3L2BMbW0t8+fPJzk5mZSUFBYuXEhjY2M/vorwiYUMgHJwIbGQA2Xg/JSB6M1AxDUor7zyCkVFRSxbtoyPP/6Y8ePHU1BQEPB13dGgqamJ8ePHs2rVqi7XP/7446xYsYLVq1dTXl7OgAEDKCgooLm52T9m/vz57Ny5kw0bNlBSUkJpaSmLFi3qr5cQNrGSAVAOzidWcqAMdE8Z6BS1GTAizJQpU4zFixf7n3d0dBiZmZlGcXGxiVWFF2C8/vrr/uc+n89wu93GE0884V9WV1dnOJ1O4+WXXzYMwzB27dplAMa2bdv8Y9566y3DZrMZhw8f7rfawyEWM2AYysHXxWIOlIFAykB0ZyCijqC0trZSUVFBfn6+f5ndbic/P5+ysjITK+tflZWVeDyegPfB5XKRm5vrfx/KyspISUlh0qRJ/jH5+fnY7XbKy8v7veZQUQbOUA6UA2VAGYjmDERUg3L8+HE6OjrIyMgIWJ6RkYHH4zGpqv53+rWe733weDykp6cHrI+LiyM1NTWi3ytl4AzlQDlQBpSBaM5ARDUoIiIiEhsiqkEZOnQoDoeD6urqgOXV1dW43W6Tqup/p1/r+d4Ht9t9zoVi7e3t1NbWRvR7pQycoRwoB8qAMhDNGYioBiUhIYGJEyeyceNG/zKfz8fGjRvJy8szsbL+lZOTg9vtDngfvF4v5eXl/vchLy+Puro6Kioq/GM2bdqEz+cjNze332sOFWXgDOVAOVAGlIGozoDZV+kGa926dYbT6TTWrFlj7Nq1y1i0aJGRkpJieDwes0sLqYaGBmP79u3G9u3bDcB46qmnjO3btxtffvmlYRiG8dhjjxkpKSnGm2++aezYscO44YYbjJycHOPUqVP+bcyaNcuYMGGCUV5ebrz//vvGZZddZsybN8+slxQysZIBw1AOzidWcqAMdE8ZiO4MRFyDYhiGsXLlSiM7O9tISEgwpkyZYmzZssXskkLu3XffNYBzHgsWLDAMo/OjZT//+c+NjIwMw+l0GjNmzDD27NkTsI0TJ04Y8+bNMwYOHGgkJycbd9xxh9HQ0GDCqwm9WMiAYSgHFxILOVAGzk8ZiN4M2AzDMPrveI2IiIjIhUXUNSgiIiISG9SgiIiIiOWoQRERERHLUYMiIiIilqMGRURERCxHDYqIiIhYjhoUERERsRw1KCIiImI5alBERETEctSgiIiIiOWoQRERERHLUYMiIiIilvP/AWYhFm2vPPbAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "greyscale = BatchGrayscale() #transforms to grayscale\n",
    "pt_stack = torch.from_numpy(stack).to(device)\n",
    "img_stack = greyscale(pt_stack)\n",
    "imglistshow(img_stack.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "557d7090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchDownsample:\n",
    "    def __init__(self, size=(110,84)):\n",
    "        self.size = size\n",
    "    \n",
    "    def __call__(self, batch: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch (torch.Tensor): expects batch to be of shape (B, C, H, W)\n",
    "        Returns:\n",
    "            torch.Tensor: batch of shape (B, C, H, W)\n",
    "        \"\"\"\n",
    "        return nn.functional.interpolate(batch, size=self.size,  mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3659ff7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAC9CAYAAACZOYZcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAha0lEQVR4nO3de3xU9Z3/8ddMLpMLuZAEcoFwVYSAgf4AY7aItkQRWleUWi+0VbHwwBIfK7GPumkpiG03/Vm3ZbVoL1Zof8J6e3hZbRu3QMXFgmIsy7ogJRDlmkSEZCYhmSQz5/dHmiFjSEgyMzlnZt7Px2MeZs5855zvTN58/eR7vnPGZhiGgYiIiIiF2M3ugIiIiMhnqUARERERy1GBIiIiIpajAkVEREQsRwWKiIiIWI4KFBEREbEcFSgiIiJiOSpQRERExHJUoIiIiIjlqEARERERyzG1QNmwYQPjxo0jISGBoqIi3n33XTO7IyZQBkQZEFAOpCfTCpTnnnuOsrIy1q5dy/vvv8/06dOZP38+9fX1ZnVJhpgyIMqAgHIgF2Yz68sCi4qKmD17Nj//+c8B8Hq95Ofnc9999/HP//zPfT7X6/Vy8uRJUlJSsNlsQ9FdCYBhGLhcLvLy8rDbz9fEykD0CEUGutorB+FDY4H0loELiR2iPvlpa2ujqqqK8vJy3za73U5JSQm7du3q0d7tduN2u333T5w4QUFBwZD0VYLn2LFjjB49GlAGolUgGQDlIFJoLJDuGeiNKQXK6dOn8Xg8ZGdn+23Pzs7mww8/7NG+oqKCdevW9dg+h4XEEheSPsZkZUFqcq+Pe4+ewOjowJ7gwJ4zEqOXStDW1o5xrgXPmbPYYmOJyRmJEd97nz1HPh5YR202YoanY0tLwejlrwebx0PHx8cHtt9uYjKGY0tKhLhYjEYXnrMNMICJtw7a2ckfSElJ8W1TBpSBgWYAlIM+RUkOlIE+hGkGemNKgTJQ5eXllJWV+e47nU7y8/OJJY5YW2gC6SmcyNlLHQDY2zu3GXYwYjp/HvnvLrwuF7FZOZyeO5aORLB5wGYARmdb7OBoNEg+1kLsrv8mJjkVZ/EEWjLs2Aywdfx9vzGd7W0eyPy4DryefvfT5nBgXDaBM1OSMWIBL9i8/m3izhmkHK0b9HthTJlI0+hE2pJtZBxoJq7qQ4z2tgHs4O99DWD6VRnoXbRkAJSDvkRLDpSB3kVaBkwpULKysoiJiaGuzv9NqqurIycnp0d7h8OBw+EYqu4BcPjrdnaU/ASPAT8/PZd2I4bpyce4NrkagBV//ga4XLRMzePu8v9g4bCD/FfLWKpbs2nyOJiZ/BGzE47xb598gT+8OZOJu4CcEUx44AA/HPUHXN4Yfnl6LgAlaf/LDEc9ZzxxlG++Gm9r/wNpTxnGoZuS+fVXfkmKvZXD7SPY6Zzk12bvp6PhucG/F0cWJ/Lla97jhvS/suLF5Vx6aBieT88MfocoA8rAwDMAykFfoiUHykDvwjUDvTGlQImPj2fmzJls27aNRYsWAZ0LnbZt20ZpaakZXeqVy4jlwNcvwdbaxhv3zOLar/+k17bfr7yFUTsMko828+LS2fz2+l/12nZ3y3gOf3UUAJU/KmDr5zcE3Nc/ugp5+q//wCW/8i+Zk9wdBLIS2gjBujNlQBkIpwyAcgDKgTIQmgz0xrRTPGVlZdx5553MmjWLK664gvXr19Pc3Mzdd99tVpcuyGvYMI4cxdPaSpwzr8+2cS4bibUt2D86RaxrEl6j9xXKrUYcHUc+AqC9ZVZQ+lqYeJTrC9KpXDbVb7vtbAKXvBeUQwSVMqAMhEsGQDkIpXDJgTIwtEwrUG699VY++eQT1qxZQ21tLTNmzKCysrLHQim5iI4Okk7ZqPhoIZkJzQBceekR0uNbWJL5F/Jjz/Fa0xT+g0yTO9qTMhAkyoCAciBhnYELMXWRbGlpqeWm8C7EluDA5vHSRwEM/H1xU5y9c6FSzMUn0Wxx8Z3/tQ9+ws3T0EjOY+9g2xCD7yyg3UbDJeN46jdxrMv746D3PRSUAWUgXDIAykEohUsOlIGhExaf4jFTRkw7a97fjgcbKfa3+mz78u0/pfm2WLyGnRR7Gyn23hc3LUw+wIyDnR8hy7C/Oej+xWRlcnjVJL63+AUmxp+/6mKcbSeZdncfz5T+UgYElANRBoaaaVeSDYTT6SQtLY1ruDFkHyvjykJc45J6fTjttf/B29xMzIgRNP3DeDoS7HCBxUPxTg+JJ5vx7t2PPTmZ1jlTcA+/cF1o8xgMe/HdAX2m3BYXj61gIq5LU/HGXnj1UmyLl8RXB/+9FrbPTaU1N4mORDsp1U6M/YcH9LGyDqOdN3mVxsZGUlNTB92P7pSBbs+J0gyAcuD3nCjNgTLQ7TkRloGwLlCmLvsXYuITzO6OXISnrZX//fV3QzIoKQPhIRQZAOUg3GgskIFkIKwLlH37R5KSYuoXMks/uFxeCgvqQzIoKQPhIRQZAOUg3GgskIFkQL9NERERsRwVKCIiImI5KlBERETEclSgiIiIiOWoQBERERHLUYEiIiIilqMCRURERCxHBYqIiIhYTkR9F8+R9lTajBizuxHV4m0eJsQ5TTu+MmA+szMAyoEVmJ0DZcB8gWYgogqUR768GM/BI2Z3I6rFTJ7ILyqfNu34yoD5zM4AKAdWYHYOlAHzBZqBiCpQ6PCAt/dvjJQh4PGae3xlwHxmZwCUAyswOwfKgPkCzIDWoIiIiIjlqEARERERy1GBIiIiIpajAkVEREQsRwWKiIiIWI4KFBEREbGcoBcoFRUVzJ49m5SUFEaOHMmiRYs4ePCgX5trrrkGm83md1uxYkWwuyImeeLnTdz4pdNMm1zHrBn1/FNpQ482ykDk656Dq+d8AsChQ4f82igHkU1jgQQi6NdB2bFjBytXrmT27Nl0dHTw3e9+l+uuu479+/eTnJzsa7ds2TIefvhh3/2kpKRgd0VM8s7uNr5+ZxKF0+Po8MCPf+QCoLm5mdTUVF87ZSCydc+B0+nllpvPctNNN3HgwAGNBVFCY4EEIugFSmVlpd/9TZs2MXLkSKqqqpg7d65ve1JSEjk5OcE+vFjAb5/J8Lv/g39J5Zo5p9m7dy+5ubm+7cpAZOueA5er84JNx44d01gQRTQWSCBCvgalsbERgIwM/6Bu3ryZrKwspk2bRnl5OefOnet1H263G6fT6XeT8NH09/85DR8+3G+7MhCdNBZEL40FMhAhvdS91+vl/vvv5/Of/zzTpk3zbb/jjjsYO3YseXl57Nu3jwcffJCDBw/y0ksvXXA/FRUVrFu3LpRdlRDxeg0e+XETAAUFBb7tykB08XoNAK688kqNBVFKY4EMVEgLlJUrV/LBBx+wc+dOv+3Lly/3/Xz55ZeTm5vLvHnzOHz4MBMnTuyxn/LycsrKynz3nU4n+fn5oeu4BM2a7zmpPtTRY7syEF1+9IPO/zE9/bT/F4cpB9FDY4EMVMhO8ZSWlvL666/z5z//mdGjR/fZtqioCIDq6uoLPu5wOEhNTfW7ifWtWe1k+zY3T20aftG2ykDkWrPayVs73ACMGjWqz7bKQWTSWCCDEfQCxTAMSktLefnll9m+fTvjx4+/6HP27t0L4LdoSsKXYRisWe3kPytb2fxcBqNHx1z0OcpA5Omeg6eeTu/Xc5SDyKKxQAIR9FM8K1euZMuWLbz66qukpKRQW1sLQFpaGomJiRw+fJgtW7awcOFCMjMz2bdvH6tWrWLu3LkUFhYGdOzGGSNIylY1bSbXqATWfM/Jq6+28qunhjMs2cbpTzq/8rylpYXU1FRlIMK5RiUA+OUgOdkGQF1dHXFxcRoLooDGAukaCwYr6AXKk08+CXRefKe7jRs3ctdddxEfH8/WrVtZv349zc3N5Ofns3jxYlavXh3wsad/579xtgf2hkhgUuNa+eWsFgBu/+oZv8deeukl7r33XmUgwqXGtQLwzP/rmYNJkyZpLIgSGgukaywYrKAXKIZh9Pl4fn4+O3bsCPZhxUJqjvlfz8Dl8lJYUM+SJUsAZSBadM9BVwYaGxt9awaUg8insUACoe/iEREREcsJ6ceMh1qeo4GUWE3pmSklJrApvUApA+YzOwOgHFiB2TlQBswXaAYiqkApTDxKuxFRLynsxNl6XudgKCkD5jM7A6AcWIHZOVAGzBdoBnSKR0RERCxHBYqIiIhYTkTNf8XYvHjxmt2NqBZjM/f9VwbMZ3YGuvqgHJjL7BwoA+YLNAMRNYMSQ98fcZbQM/t3YPbxxRq/Ayv0IdqZ/Tsw+/gS+O8gogoUERERiQwqUERERMRyImoNSkH8p2Z3QUymDAgoB6IMRIKIKlCyYxzYNSlkKi9e6jxu046vDJjP7AyAcmAFZudAGTBfoBmIqAIllhhibAqkmTyGzdTjKwPmMzsDoBxYgdk5UAbMF2gG9NsTERERy4moGZSqNg/ei3ybsoSW3eYlJ8a84ysD5jM7A6AcWIHZOVAGzBdoBiKqQDnWnkmrEWd2N6Jagq2dnJiTph1fGTCf2RkA5cAKzM6BMmC+QDMQUQXKp55hnPPGm92NqJZkbzP1+MqA+czOACgHVmB2DpQB8wWaAa1BEREREcuJqBmUvU1jcLYnmN2NqJYa18r1yX8z7fjKgPnMzgAoB1Zgdg6UAfMFmoGIKlDe/2Q0rhaH2d2IaimJbsg27/jKgPnMzgAoB1Zgdg6UAfMFmoGIKlDOupJoO6dFUWbyeMw9a6gMmM/sDIByYAVm50AZMF+gGYioAsUwAAtcJCqaGSa//8qA+czOQGcfUA5MZnYOlAHzBZqBoBcoDz30EOvWrfPbdtlll/Hhhx8C0NraygMPPMCzzz6L2+1m/vz5PPHEE2RnBz4X2H4uHluTyRdgiHJttjjW/9TFv/2sudc2ykBka7N1/tV6oRzMmjWLv/2t85y0chDZNBZI11gwWCGZQZk6dSpbt249f5DY84dZtWoVv//973nhhRdIS0ujtLSUm2++mbfffjvg407YbOA4+knA+5HBax2fAQUwaVIsz/z7cACamrx88erzX9ylDES21vEZMK/z564cdGXgjTfe8LVTDiKbxgLpPhYMRkgKlNjYWHJycnpsb2xs5De/+Q1btmzhi1/8IgAbN25kypQp7N69myuvvDKg4zqOnsVz6EhA+5DAJNjtUAAxsTBiZOdfLwmJ56f5lIHIl2A/f965KwddGcjMzASUg2igsUC6jwWDEZIC5dChQ+Tl5ZGQkEBxcTEVFRWMGTOGqqoq2tvbKSkp8bWdPHkyY8aMYdeuXb0G0u1243af/0ZEp9MZim5LEH1U46FoZj2OBBuXX34+ZspAdOnKQdzfr5d17Ngxpk6dqhxEEY0FMlhBX2ZdVFTEpk2bqKys5Mknn6SmpoarrroKl8tFbW0t8fHxpKen+z0nOzub2traXvdZUVFBWlqa75afnx/sbksQzfhcPD/5aRqbnhnOD36UyokTHgBlIMp0z8HqNSkALFiwQDmIIhoLJBBBn0FZsGCB7+fCwkKKiooYO3Yszz//PImJiYPaZ3l5OWVlZb77TqdTobSwa75w/toDU6bAJZfGMOfK07z88stkZGQMap/KQPjpnoPRozun+BsbGzUWRBGNBRKIkH/MOD09nUmTJlFdXc21115LW1sbDQ0NflVzXV3dBdesdHE4HDgcuuBOuEpN7ZyoO3LkCAUFBcpAFJs4caLGgiimsUAGIuRX0mlqauLw4cPk5uYyc+ZM4uLi2LZtm+/xgwcPcvToUYqLi0PdFTHJuWYvADk5OcpAlKupqdFYEMU0FshABH0G5dvf/jY33HADY8eO5eTJk6xdu5aYmBhuv/120tLSuOeeeygrKyMjI4PU1FTuu+8+iouLA16xLdbxox84mVeSwOjRdurqvDz6iAuAr3zlK8pAFOmeg5qazrUHGguii8YCCUTQC5Tjx49z++238+mnnzJixAjmzJnD7t27GTFiBAA/+9nPsNvtLF682O/CPBI5ak95+afSBhoavGRk2Jnxuc6L9WRlZQHKQLTonoP04Z2TtVu3btVYEEU0Fkgggl6gPPvss30+npCQwIYNG9iwYUOwDy0W8fgT6X73XS4vlX+s991XBqJD9xy4XF4KC+qZMGGCb5tyEPk0FkggzP9WLxEREZHPUIEiIiIilqMCRURERCxHBYqIiIhYjgoUERERsRwVKCIiImI5KlBERETEclSgiIiIiOWoQBERERHLUYEiIiIilhP0S93LwNgcDvAaGB4PeD1md0dERMQSVKCYrOmGGTjOduA4ehbPoSNmd0dERMQSdIrHZKcL7Zy5zEF7dqrZXREREbEMFSgmi2uyEXfOIMat0zvRJCYzg5jLLsGekGB2V0RELEkFisnSD3lI/diN/WyT2V2RIWSMzubTK0ZgS0kBm83s7oiIWI7WoJgs6eV3AND8SXQ5Oy0N5z82kVk1HNvZsxgdHWZ3SUTEUjSDImICh9OL+1QStLVjeA2zuyNDyWYjpmAS9qQks3siYmkqUERMMOyvJ7h0SwvGqXp9vDzK2GLj+HDlcJgwxuyuiFiaTvGImKDj+Ak4fgKv2R2RoWe3MePyI7jSR+kvRJE+6N+HiMgQqz+Xgs2jU3vRxp6QgD052exuhA3NoIiIDCHD7SZ54cc6tReFPnrw/9A6qp1Jy/eY3ZWwEPQZlHHjxmGz2XrcVq5cCcA111zT47EVK1YEuxtiojnF9YzPr/XdCgvqAXjggQcAZSBadM9BVwbS0tI0FkDUFCcaCz7DBtg1c9ZfQZ9B2bNnDx7P+X98H3zwAddeey233HKLb9uyZct4+OGHffeTtJo9orz6ehbebtPXe//azvJvNrBo0SLfNmUg8nXPQVOTly9e/SmAxoIoorHAX/aedloP6cRFfwX9nRoxYoTf/R//+MdMnDiRq6++2rctKSmJnJycYB9aLCIz039ibseOzovQzZkzx7dNGYh83XOQkNh5Mbrx48drLIgiGgv8OX6/B4fZnQgjIV0k29bWxjPPPMPSpUuxdbta5ubNm8nKymLatGmUl5dz7ty5PvfjdrtxOp1+NwkPbW0Gv3+tFUAZiGLtbZ1/RX/ta19TDqKUxgIZqJDONb3yyis0NDRw1113+bbdcccdjB07lry8PPbt28eDDz7IwYMHeemll3rdT0VFBevWrQtlVyVE/vONVlwu/3OuykD02b7NDcCSJUt825SD6KKxQAbKZhhGyFbszJ8/n/j4eF577bVe22zfvp158+ZRXV3NxIkTL9jG7Xbjdrt9951OJ/n5+ezbP5KUlPOTQCvmfQPPoSPBewEyYDGXXcIv/rTJd/8bS85gs8Nbb7bR2NhIamrPb21WBiLLZzMAsOS2M/zl7d4zAMpBpNFYIBcaC1wuL4UF9X2OBV1Cdorn448/ZuvWrXzzm9/ss11RUREA1dXVvbZxOBykpqb63cT6jh/38PbONhYvTuyznTIQ2Y4f97B7V9tF2ykHkUtjgQxGyAqUjRs3MnLkSL70pS/12W7v3r0A5ObmhqorYpIXnz9HZpadq66O77OdMhDZXnz+HBkZFx9qlIPIpbFABiMka1C8Xi8bN27kzjvvJDb2/CEOHz7Mli1bWLhwIZmZmezbt49Vq1Yxd+5cCgsLQ9EVMYnXa/DC8y0s/koisbHnF8QpA9GlKwf/uCiBp586v/hROYgeGgtksEJSoGzdupWjR4+ydOlSv+3x8fFs3bqV9evX09zcTH5+PosXL2b16tWh6IaYaOd/tXHyhJdbbvWf0lUGoktXDhbd7F+gKAfRQ2OBDFZICpTrrruOC629zc/PZ8eOHaE4pFjM3Ksd1BzrvLaBy3X+K/GUgejSlYPuGQDlIJpoLJDB0pcFioiIiOWoQBERERHLUYEiIiIilqMCRURERCxHBYqIiIhYjgoUERERsRwVKCIiImI5KlBERETEclSgiIiIiOWoQBERERHLUYEiIiIilqMCRURERCxHBYqIiIhYjgoUERERsRwVKCIiImI5KlBERETEclSgiIiIiOWoQBERERHLUYEiIiIilqMCRURERCxHBYqIiIhYzoALlLfeeosbbriBvLw8bDYbr7zyit/jhmGwZs0acnNzSUxMpKSkhEOHDvm1OXPmDEuWLCE1NZX09HTuuecempqaAnohMnTOGp+w13ibt4zX2Wq8SL1xwu9xwzD46aMurphZz+RLalm29GyPfSgD4U0ZEFAOJLRiB/qE5uZmpk+fztKlS7n55pt7PP7II4/w2GOP8dvf/pbx48fz/e9/n/nz57N//34SEhIAWLJkCadOneJPf/oT7e3t3H333SxfvpwtW7YMqC/nvHbs3uieBLLFxWOfNL5/jU/U4m1qxujoCOiYHjoYRhp5jGMfu/wfNAwe3eDmd0+f4/v/mkVefixP/N+zQDutra2kpqYCykAwRXsGQDnoj5jhwyEnC+z9eJ/a2vHWHL1oTqyUA2Ug9GInjMNIiAeb7aJtbWcaMQyDWo/Db3uzx9v/4w20gwsWLGDBggUXfMwwDNavX8/q1au58cYbAfjd735HdnY2r7zyCrfddhsHDhygsrKSPXv2MGvWLAAef/xxFi5cyKOPPkpeXl6/+/K+ezSJcedfgq3DM9CXE/ZiRuUw/Nd1/Wr70b9OJu2d43QcP3Hxxn3IsuWSRW7nHeMzD7rbePopN5PvnM3eywvZC4y8vwnefJbXX3+dpUuXKgNBFu0ZAOWgP84svIyUpSfITnT12a7VE8v+uhzG35dFx6naPttaKQfKQGjZ4uLZvzqLy8adIiuhuc+2rZ5Y9ldOYvzm4zx26lq/x9qb24Df9euYQS03a2pqqK2tpaSkxLctLS2NoqIidu3qrK537dpFenq6L4wAJSUl2O123nnnnQvu1+1243Q6/W5iTS0djbR+2kLO7FG+bXHD4gHYs2cPoAxEulBlAJSDcKKxQAI14BmUvtTWdlbb2dnZftuzs7N9j9XW1jJy5Ej/TsTGkpGR4WvzWRUVFaxbty6YXY0Y3k8+5aOfTutX27SqU3jP9DwHHExuzzkAEjISezxWV9f5V74yEFzRkgFQDgKR8U4dTc25fBR7kVkJA7KbvXjPNgR0PI0FkcXoaGfCMwbnUkfxUexFTvEYMOajxoCPGdQCJVTKy8spKyvz3Xc6neTn53OsLZOEtrjzDY3PzjFGPm9zM8kv9v4XZ3eBrTroH8PtBmDPvonEpnWeY/a2tAa8X2Wgd9GSAVAOAuGpriGxuqbf7fu/UuDCNBZEGMMgdntVv4sGAzCyR/KXqsv8tg8kA0EtUHJycoDO6jg3N9e3va6ujhkzZvja1NfX+z2vo6ODM2fO+J7/WQ6HA4fD0WP7GycKiEk+vz2z/VygL0ECFHumBYDR39tFii0dgA6jnWOcn1lTBiJbqDIAykE40Vggnrp6Lr3vM7/fv2egP4JaoIwfP56cnBy2bdvmK0icTifvvPMO9957LwDFxcU0NDRQVVXFzJkzAdi+fTter5eioqIBHS/1qx8TaztfMXd4tSjKbIkkE08CZ6gnhXQAOmgHYPbs2YAyEOmGOgOgHFiRxgIJ1IALlKamJqqrq333a2pq2Lt3LxkZGYwZM4b777+fH/7wh1x66aW+jxnn5eWxaNEiAKZMmcL111/PsmXL+MUvfkF7ezulpaXcdtttA165j9cDNn2sbKh1GB20cP46BS004zIaiCOeBFsSY4xLqOEAScYwEknmEP8DwJe//GVAGYgElsoAKAcmsVQOlIGIM+AC5b333uMLX/iC737XucA777yTTZs28Z3vfIfm5maWL19OQ0MDc+bMobKy0ncNFIDNmzdTWlrKvHnzsNvtLF68mMceeywIL0eGgpMzvM9bvvuH2AdALmOZymzGchkePBygig7aSSUDQBmIIMqAgHIgoWUzjPBbSeR0OklLS+MabvSb0hNr6jDaeZNXaWxs9F2cKVDKQHgJRQZAOQg3GgtkIBnQfJiIiIhYjgoUERERsRwVKCIiImI5KlBERETEcsLiSrKf1bWut4P2nl9QJZbTde2DYK7HVgbCSygy0H1/ykF40FggA8lAWBYoLlfnt3Hu5A8m90QGwuVykZaWFrR9gTIQboKZga79gXIQbjQWSH8yEJYfM/Z6vRw8eJCCggKOHTsW1I8thgvf90+Ewes3DAOXy0VeXh52e3DOKioDygAoB6AcKAORm4GwnEGx2+2MGtX5Fd6pqamW/4WEUri8/mD+1QzKQHfh8vqDnQFQDroLl9evsSB0wuX19zcDWiQrIiIilqMCRURERCwnbAsUh8PB2rVrL/i129Eg2l8/6D2I9tffJdrfh2h//aD3IFJff1gukhUREZHIFrYzKCIiIhK5VKCIiIiI5ahAEREREctRgSIiIiKWowJFRERELCcsC5QNGzYwbtw4EhISKCoq4t133zW7SyHx0EMPYbPZ/G6TJ0/2Pd7a2srKlSvJzMxk2LBhLF68mLq6OhN7PLSUg07RnANloJMyoAxEYgbCrkB57rnnKCsrY+3atbz//vtMnz6d+fPnU19fb3bXQmLq1KmcOnXKd9u5c6fvsVWrVvHaa6/xwgsvsGPHDk6ePMnNN99sYm+HjnKgHCgDyoAyEOEZMMLMFVdcYaxcudJ33+PxGHl5eUZFRYWJvQqNtWvXGtOnT7/gYw0NDUZcXJzxwgsv+LYdOHDAAIxdu3YNUQ/Noxx0iuYcKAOdlAFlIFIzEFYzKG1tbVRVVVFSUuLbZrfbKSkpYdeuXSb2LHQOHTpEXl4eEyZMYMmSJRw9ehSAqqoq2tvb/d6LyZMnM2bMmIh9L7ooB8qBMqAMKAORn4GwKlBOnz6Nx+MhOzvbb3t2dja1tbUm9Sp0ioqK2LRpE5WVlTz55JPU1NRw1VVX4XK5qK2tJT4+nvT0dL/nROp70Z1yoBwoA8qAMhD5GYg1uwPSuwULFvh+LiwspKioiLFjx/L888+TmJhoYs9kKCkHogxINGYgrGZQsrKyiImJ6bEyua6ujpycHJN6NXTS09OZNGkS1dXV5OTk0NbWRkNDg1+baHgvlAPlQBlQBpSByM9AWBUo8fHxzJw5k23btvm2eb1etm3bRnFxsYk9GxpNTU0cPnyY3NxcZs6cSVxcnN97cfDgQY4ePRrx74VyoBwoA8qAMhAFGTB7le5APfvss4bD4TA2bdpk7N+/31i+fLmRnp5u1NbWmt21oHvggQeMN99806ipqTHefvtto6SkxMjKyjLq6+sNwzCMFStWGGPGjDG2b99uvPfee0ZxcbFRXFxscq+HhnKgHCgDyoAyENkZCLsCxTAM4/HHHzfGjBljxMfHG1dccYWxe/dus7sUErfeequRm5trxMfHG6NGjTJuvfVWo7q62vd4S0uL8a1vfcsYPny4kZSUZNx0003GqVOnTOzx0FIOOkVzDpSBTsqAMhCJGbAZhmGYPYsjIiIi0l1YrUERERGR6KACRURERCxHBYqIiIhYjgoUERERsRwVKCIiImI5KlBERETEclSgiIiIiOWoQBERERHLUYEiIiIilqMCRURERCxHBYqIiIhYzv8H/A3C+1dm0lEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_downsample = BatchDownsample(size=(110,84))\n",
    "downsampled_stack = batch_downsample(img_stack)\n",
    "imglistshow(downsampled_stack.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1dc85b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchCrop:\n",
    "    def __init__(self, size=(84,84)):\n",
    "        self.size = size\n",
    "    \n",
    "    def __call__(self, batch: torch.Tensor):\n",
    "        \"\"\" crop 17 pixels from top and bottom\n",
    "        Args:\n",
    "            batch (torch.Tensor): expects batch to be of shape (B, C, H, W)\n",
    "        Returns:\n",
    "            torch.Tensor: batch of shape (B, C, H, W)\n",
    "        \"\"\"\n",
    "        return batch[:, :,  17:17+self.size[0], :] # crop 17 pixels from top and bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7fb34dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_downsample = BatchCrop(size=(84,84))\n",
    "batch_downsample = batch_downsample(downsampled_stack)\n",
    "imglistshow(batch_downsample.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "084ae4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchToTensor:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, batch: np.array):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch (np.array): expects a numpy array\n",
    "        Returns:\n",
    "            torch.Tensor: torch tensor on device\n",
    "        \"\"\"\n",
    "        return torch.from_numpy(batch).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e0eb71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformPipeline:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __call__(self, batch: torch.Tensor):\n",
    "        for transform in self.transforms:\n",
    "            batch = transform(batch)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "33e8702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TransformPipeline([BatchToTensor(device), BatchGrayscale(), BatchDownsample(), BatchCrop()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "2c7b4df0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:54:53.606848Z",
     "iopub.status.busy": "2024-01-20T09:54:53.605953Z",
     "iopub.status.idle": "2024-01-20T09:54:53.684011Z",
     "shell.execute_reply": "2024-01-20T09:54:53.683413Z",
     "shell.execute_reply.started": "2024-01-20T09:54:53.606814Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1705481786623,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "2c7b4df0"
   },
   "outputs": [],
   "source": [
    "env = TorchEnv(gym.make(environment))\n",
    "s = env.reset()\n",
    "preprocessed_s_prime = pipeline(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083ac764",
   "metadata": {
    "id": "083ac764"
   },
   "source": [
    "## fill replay memory\n",
    "here we fill the replay memory with downsampled cropped stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "f0da8610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T23:01:05.022694Z",
     "iopub.status.busy": "2024-01-20T23:01:05.022171Z",
     "iopub.status.idle": "2024-01-20T23:01:05.026049Z",
     "shell.execute_reply": "2024-01-20T23:01:05.025647Z",
     "shell.execute_reply.started": "2024-01-20T23:01:05.022672Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1705481769031,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "f0da8610"
   },
   "outputs": [],
   "source": [
    "class ExperienceReplay:\n",
    "    def __init__(self, maxlen: int) -> None:\n",
    "        self.deque = deque(maxlen=maxlen)\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def append(self, x):\n",
    "        self.deque.append(x)\n",
    "\n",
    "    def sample(self, bs):\n",
    "        return random.sample(self.deque, min(len(self), bs))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.deque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "9eac8602",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:55:12.606898Z",
     "iopub.status.busy": "2024-01-20T09:55:12.606299Z",
     "iopub.status.idle": "2024-01-20T09:55:12.613809Z",
     "shell.execute_reply": "2024-01-20T09:55:12.612768Z",
     "shell.execute_reply.started": "2024-01-20T09:55:12.606867Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1705481796263,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "9eac8602"
   },
   "outputs": [],
   "source": [
    "def fill(replay_memory:ExperienceReplay, env:TorchEnv, fill_size:int = replay_start_size) -> None :\n",
    "    while len(replay_memory)<fill_size:\n",
    "        s = env.reset()\n",
    "        terminated=False\n",
    "        while terminated == False and len(replay_memory)<fill_size:\n",
    "            a = env.sample()\n",
    "            s_prime, r, terminated = env.step(a)\n",
    "            s_prime = torch.cat([s, s_prime])[-4:]\n",
    "            replay_memory.append((s, a, r, s_prime, terminated))\n",
    "            s = s_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "cf2af673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step_returns_correct_shape():\n",
    "    env = TorchEnv(gym.make(environment), transforms=pipeline)\n",
    "    s = env.reset()\n",
    "    a = env.sample()\n",
    "    s_prime, r, terminated = env.step(a)\n",
    "    s_prime = torch.cat([s, s_prime])[-4:]\n",
    "    assert s_prime.shape == (4, 1, 84, 84), f\"s_prime should be of shape (4, 1, 84, 84), but is {s_prime.shape}\"\n",
    "\n",
    "test_step_returns_correct_shape()\n",
    "\n",
    "def test_step_different_state():\n",
    "    env = TorchEnv(gym.make(environment), transforms=pipeline)\n",
    "    s = env.reset()\n",
    "    a = env.sample()\n",
    "    s_prime, r, terminated = env.step(a)\n",
    "    s_prime = torch.cat([s, s_prime])[-4:]\n",
    "    assert not torch.all(torch.eq(s, s_prime)), \"s and s_prime should be different\"\n",
    "\n",
    "test_step_different_state()\n",
    "\n",
    "def test_should_return_correct_number_of_samples():\n",
    "    env = TorchEnv(gym.make(environment), transforms=pipeline)\n",
    "    replay_memory = ExperienceReplay(replay_memory_size)\n",
    "    fill(replay_memory, env, fill_size=10)\n",
    "    samples = replay_memory.sample(3)\n",
    "    assert len(samples) == 3\n",
    "\n",
    "test_should_return_correct_number_of_samples()\n",
    "def test_sample_should_contain_5_elements():\n",
    "    env = TorchEnv(gym.make(environment), transforms=pipeline)\n",
    "    replay_memory = ExperienceReplay(replay_memory_size)\n",
    "    fill(replay_memory, env, fill_size=10)\n",
    "    samples = replay_memory.sample(3)\n",
    "    assert len(samples[0]) == 5 # s, a, r, s_prime, terminated\n",
    "\n",
    "test_sample_should_contain_5_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "5d0c4934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 84, 84])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = TorchEnv(gym.make(environment), transforms=pipeline)\n",
    "replay_memory = ExperienceReplay(replay_memory_size)\n",
    "fill(replay_memory, env, fill_size=10)\n",
    "samples = replay_memory.sample(3)\n",
    "s, a, r, s_prime, terminated = samples[0]\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "bbcdfc51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "execution": {
     "iopub.execute_input": "2024-01-20T09:45:58.012967Z",
     "iopub.status.busy": "2024-01-20T09:45:58.012448Z",
     "iopub.status.idle": "2024-01-20T09:45:58.124692Z",
     "shell.execute_reply": "2024-01-20T09:45:58.124255Z",
     "shell.execute_reply.started": "2024-01-20T09:45:58.012945Z"
    },
    "executionInfo": {
     "elapsed": 423,
     "status": "ok",
     "timestamp": 1705481800746,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "bbcdfc51",
    "outputId": "89ee91f7-27f6-49a5-9c7f-0108126bcb68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imglistshow(s.squeeze(1).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2554b07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:46:00.138370Z",
     "iopub.status.busy": "2024-01-20T09:46:00.137619Z",
     "iopub.status.idle": "2024-01-20T09:46:00.144896Z",
     "shell.execute_reply": "2024-01-20T09:46:00.144416Z",
     "shell.execute_reply.started": "2024-01-20T09:46:00.138345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.data_types.image.Image at 0x7f4cfd5bf3d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.Image(s[:2].cpu(), caption=\"Top: Frame at t , Bottom: Frame at t+1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee5f456",
   "metadata": {
    "id": "bee5f456"
   },
   "source": [
    "## Define the Atari DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e03eb896",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:57:32.218494Z",
     "iopub.status.busy": "2024-01-20T09:57:32.217811Z",
     "iopub.status.idle": "2024-01-20T09:57:32.224470Z",
     "shell.execute_reply": "2024-01-20T09:57:32.224033Z",
     "shell.execute_reply.started": "2024-01-20T09:57:32.218470Z"
    }
   },
   "outputs": [],
   "source": [
    "class DQNDeepmind2013(nn.Module):\n",
    "    def __init__(self, n_actions):\n",
    "        super(DQNDeepmind2013, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, 8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32*9*9, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self, s):\n",
    "        return self.conv(s) \n",
    "    \n",
    "class DQNDeepmind2015(nn.Module):\n",
    "    def __init__(self, n_actions):\n",
    "        super(DQNDeepmind2015, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, 8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self, s):\n",
    "        return self.conv(s) \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ad53db6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:57:36.382102Z",
     "iopub.status.busy": "2024-01-20T09:57:36.381416Z",
     "iopub.status.idle": "2024-01-20T09:57:36.386601Z",
     "shell.execute_reply": "2024-01-20T09:57:36.386210Z",
     "shell.execute_reply.started": "2024-01-20T09:57:36.382078Z"
    },
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1705481813206,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "ad53db6c"
   },
   "outputs": [],
   "source": [
    "class AtariDQN(nn.Module):\n",
    "    def __init__(self, net, n_actions, normalize=True):\n",
    "        super(AtariDQN, self).__init__()\n",
    "        self.net = net\n",
    "        self.n_actions = n_actions\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def forward(self, s: torch.Tensor):\n",
    "        '''\n",
    "        Args:\n",
    "            s (torch.Tensor): batch of shape (B, H, W)\n",
    "        Returns:\n",
    "            torch.Tensor: batch of shape (B, n_actions)\n",
    "        '''\n",
    "        if self.normalize:\n",
    "            s = s.float() / 255.0\n",
    "        return self.net(s)\n",
    "\n",
    "    def select_next_action(self, s, epsilon):\n",
    "        with torch.no_grad():\n",
    "            use_greedy = np.random.binomial(1, 1-epsilon)\n",
    "            if use_greedy:\n",
    "                a = self(s).argmax().item()\n",
    "            else:\n",
    "                a = np.random.randint(self.n_actions)\n",
    "            return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "7298055d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:57:38.319912Z",
     "iopub.status.busy": "2024-01-20T09:57:38.319145Z",
     "iopub.status.idle": "2024-01-20T09:57:38.343313Z",
     "shell.execute_reply": "2024-01-20T09:57:38.342791Z",
     "shell.execute_reply.started": "2024-01-20T09:57:38.319886Z"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1705481815123,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "7298055d"
   },
   "outputs": [],
   "source": [
    "dqn = AtariDQN(DQNDeepmind2015(env.n_actions).to(device), n_actions=env.n_actions).to(device)\n",
    "if BASE_MODEL is not None:\n",
    "    dqn.load_state_dict(torch.load(BASE_MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "16d27f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.uint8"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0][0].squeeze(1).unsqueeze(0).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "b72ac1cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-20T09:57:44.752327Z",
     "iopub.status.busy": "2024-01-20T09:57:44.751896Z",
     "iopub.status.idle": "2024-01-20T09:57:44.853896Z",
     "shell.execute_reply": "2024-01-20T09:57:44.853289Z",
     "shell.execute_reply.started": "2024-01-20T09:57:44.752298Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1705481817498,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "b72ac1cb",
    "outputId": "fead66f6-f24a-46bd-dffd-bf4d7238f945"
   },
   "outputs": [],
   "source": [
    "out = dqn(samples[0][0].squeeze(1).unsqueeze(0)).squeeze(0)\n",
    "assert out.shape[0] == env.n_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829732d1",
   "metadata": {
    "id": "829732d1"
   },
   "source": [
    "# Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "9f74bba5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-20T09:57:56.904290Z",
     "iopub.status.busy": "2024-01-20T09:57:56.903347Z",
     "iopub.status.idle": "2024-01-20T09:57:56.921882Z",
     "shell.execute_reply": "2024-01-20T09:57:56.921441Z",
     "shell.execute_reply.started": "2024-01-20T09:57:56.904253Z"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1705481838021,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "6813a739",
    "outputId": "6bfe645a-b84d-491e-f374-b356f68b6006"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_net = AtariDQN(DQNDeepmind2015(env.n_actions).to(device), n_actions=env.n_actions).to(device)\n",
    "target_net.load_state_dict(dqn.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "6813a739",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-20T09:58:06.802828Z",
     "iopub.status.busy": "2024-01-20T09:58:06.802260Z",
     "iopub.status.idle": "2024-01-20T09:58:06.807862Z",
     "shell.execute_reply": "2024-01-20T09:58:06.807292Z",
     "shell.execute_reply.started": "2024-01-20T09:58:06.802804Z"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1705481838021,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "6813a739",
    "outputId": "6bfe645a-b84d-491e-f374-b356f68b6006"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtariDQN(\n",
       "  (net): DQNDeepmind2015(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "      (7): Linear(in_features=3136, out_features=512, bias=True)\n",
       "      (8): ReLU()\n",
       "      (9): Linear(in_features=512, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = Optimizer(dqn.parameters(),  lr=lr)\n",
    "dqn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "85da894e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:58:31.955949Z",
     "iopub.status.busy": "2024-01-20T09:58:31.955285Z",
     "iopub.status.idle": "2024-01-20T09:58:31.960596Z",
     "shell.execute_reply": "2024-01-20T09:58:31.960147Z",
     "shell.execute_reply.started": "2024-01-20T09:58:31.955918Z"
    },
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1705481860023,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "85da894e"
   },
   "outputs": [],
   "source": [
    "def atari_collate(batch):\n",
    "    s_j, a_j, r_j, s_prime_j, terminated_j = list(zip(*batch))\n",
    "    return (torch.stack(s_j).squeeze(2).to(device), \n",
    "            torch.tensor(a_j).to(device), \n",
    "            torch.tensor(r_j).to(device), \n",
    "            torch.stack(s_prime_j).squeeze(2).to(device), \n",
    "            (~torch.tensor(terminated_j)).to(device).half()\n",
    "    )\n",
    "def get_batch_efficient(self, batch, target_net=None, collate_fn=None):\n",
    "    if target_net is None:\n",
    "        target_net = self\n",
    "    s, a, r, s_prime, not_terminated = collate_fn(batch)\n",
    "\n",
    "    y_hat = self(s).gather(1, a.unsqueeze(1)).squeeze() # gather the values at the indices given by the actions a\n",
    "\n",
    "    next_values, _ = target_net(s_prime).max(dim=1)\n",
    "    next_values = next_values.clone().detach()\n",
    "    y_j = r.detach().clone() + gamma * next_values * not_terminated # if terminated then not_terminated is set to zero (y_j = r)\n",
    "    return y_hat, y_j\n",
    "\n",
    "def get_epsilon(epsilon, final_epsilon=0.1, steps_to_anneal=final_exploration_frame):\n",
    "    if epsilon > final_epsilon:\n",
    "        epsilon -= (1/steps_to_anneal) * (1-final_epsilon)\n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "0c367002",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-20T09:58:34.394285Z",
     "iopub.status.busy": "2024-01-20T09:58:34.393473Z",
     "iopub.status.idle": "2024-01-20T09:58:34.398973Z",
     "shell.execute_reply": "2024-01-20T09:58:34.398239Z",
     "shell.execute_reply.started": "2024-01-20T09:58:34.394248Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1705481873718,
     "user": {
      "displayName": "Gareth Davies",
      "userId": "11833826550098318581"
     },
     "user_tz": 0
    },
    "id": "0c367002",
    "outputId": "39c78315-d9ae-4f54-fc36-1cb33346a2e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = FRAMES_TO_TRAIN // EPOCH_SIZE\n",
    "print(n_epochs)\n",
    "track = False\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss, epoch_reward, k, epoch_episodes = 0, 0, 0, 0\n",
    "    while k < EPOCH_SIZE:\n",
    "        terminated = False\n",
    "        s = env.reset()\n",
    "        while terminated == False:\n",
    "            a = dqn.select_next_action(s.squeeze(1).unsqueeze(0), epsilon)\n",
    "            s_prime, r, terminated = env.step(a)\n",
    "            s_prime = torch.cat([s, s_prime])[-4:]\n",
    "            replay_memory.append((s, a, r, s_prime, terminated))\n",
    "            epsilon = get_epsilon(epsilon)\n",
    "            s = s_prime\n",
    "\n",
    "            if len(replay_memory) > replay_start_size:\n",
    "                optimizer.zero_grad()\n",
    "                batch = replay_memory.sample(bs)\n",
    "                y_hat, y = get_batch_efficient(dqn, batch, target_net=target_net, collate_fn=atari_collate)\n",
    "                loss = loss_fn(y_hat, y)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_value_(dqn.parameters(), max_grad_norm)\n",
    "                optimizer.step()\n",
    "                        \n",
    "                if k % sync_every_n_steps == 0:\n",
    "                    target_net.load_state_dict(dqn.state_dict())\n",
    "            \n",
    "                epoch_loss += loss.item()\n",
    "            epoch_reward += r\n",
    "            k += 1\n",
    "        epoch_episodes += 1\n",
    "    \n",
    "    if track:\n",
    "        torch.save(dqn.state_dict(), 'breakout.pt')\n",
    "        wandb.log_model(name=f\"breakout-{wandb.run.id}\", path='breakout.pt')\n",
    "        wandb.log({\"epoch\":epoch,\n",
    "                \"step_loss\": epoch_loss / k, \n",
    "                \"reward\": epoch_reward / epoch_episodes,\n",
    "                \"step\":k,\n",
    "                \"epsilon\": epsilon\n",
    "                })\n",
    "    print(f'epochs {epoch}, step_loss {epoch_loss / k}, reward {epoch_reward / epoch_episodes}, k {k}, epsilon {epsilon}')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "09af120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dqn_should_return_correct_s_shape_given_batch():\n",
    "    batch = replay_memory.sample(3)\n",
    "    s_j, a_j, r_j, s_prime_j, terminated_j = list(zip(*batch))\n",
    "    s_j = torch.stack(s_j).squeeze(2)\n",
    "    assert dqn(s_j).shape == torch.Size([3, 4])\n",
    "\n",
    "test_dqn_should_return_correct_s_shape_given_batch()\n",
    "def test_action_shape_should_be_correct_give_atari_collate():    \n",
    "    batch = replay_memory.sample(3)\n",
    "    _, a_j, r_j, s_prime_j, terminated_j = atari_collate(batch)\n",
    "    assert a_j.shape == torch.Size([3])\n",
    "\n",
    "test_action_shape_should_be_correct_give_atari_collate()\n",
    "\n",
    "def test_reward_shape_should_be_correct_give_atari_collate():\n",
    "    batch = replay_memory.sample(3)\n",
    "    _, a_j, r_j, s_prime_j, terminated_j = atari_collate(batch)\n",
    "    assert r_j.shape == torch.Size([3])\n",
    "\n",
    "test_reward_shape_should_be_correct_give_atari_collate()\n",
    "\n",
    "def test_s_shape_should_be_correct_give_atari_collate():\n",
    "    batch = replay_memory.sample(3)\n",
    "    s, _, _, _, _ = atari_collate(batch)\n",
    "    assert s.shape == torch.Size([3, 4, 84, 84])\n",
    "\n",
    "test_s_shape_should_be_correct_give_atari_collate()\n",
    "\n",
    "def test_s_prime_shape_should_be_correct_give_atari_collate():\n",
    "    batch = replay_memory.sample(3)\n",
    "    _, _, _, s, _ = atari_collate(batch)\n",
    "    assert s.shape == torch.Size([3, 4, 84, 84])\n",
    "\n",
    "test_s_prime_shape_should_be_correct_give_atari_collate()\n",
    "\n",
    "def test_not_terminated_shape_should_be_correct_give_atari_collate():\n",
    "    batch = replay_memory.sample(3)\n",
    "    _, _, _, _, t = atari_collate(batch)\n",
    "    assert t.shape == torch.Size([3])\n",
    "\n",
    "test_not_terminated_shape_should_be_correct_give_atari_collate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "48c25800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 84, 84])\n",
      "torch.Size([4, 1, 84, 84])\n"
     ]
    }
   ],
   "source": [
    "def test_should_select_action_as_integer_given_epsilon_one():\n",
    "    env = TorchEnv(gym.make(environment), transforms=pipeline)\n",
    "    s = env.reset()\n",
    "    print(s.shape)\n",
    "    a = dqn.select_next_action(s.to(device), 1)\n",
    "    assert isinstance(a, int)\n",
    "\n",
    "test_should_select_action_as_integer_given_epsilon_one()\n",
    "\n",
    "def test_should_assign_s_and_s_prime_same_shapes():\n",
    "    env = TorchEnv(gym.make(environment), transforms=pipeline)\n",
    "    s = env.reset()    \n",
    "    s_prime, r, terminated = env.step(a)\n",
    "    s_prime = torch.cat([s, s_prime])[-4:]\n",
    "    assert s_prime.shape == s.shape\n",
    "\n",
    "test_should_assign_s_and_s_prime_same_shapes()\n",
    "\n",
    "\n",
    "def test_should_select_action_as_integer_given_epsilon_zero():\n",
    "    env = TorchEnv(gym.make(environment), transforms=pipeline)\n",
    "    s = env.reset()\n",
    "    print(s.shape)\n",
    "    a = dqn.select_next_action(s.squeeze(1).unsqueeze(0).to(device), 0)\n",
    "    assert isinstance(a, int)\n",
    "\n",
    "test_should_select_action_as_integer_given_epsilon_zero()\n",
    "def test_should_assign_state_with_uint8_dtype():\n",
    "    env = TorchEnv(gym.make(environment), transforms=pipeline)\n",
    "    s = env.reset()    \n",
    "    s_prime, r, terminated = env.step(a)\n",
    "    s_prime = torch.cat([s, s_prime])[-4:]\n",
    "    assert s_prime.dtype == torch.uint8\n",
    "\n",
    "test_should_assign_state_with_uint8_dtype()\n",
    "def test_should_assign_state_with_uint8_dtype():\n",
    "    env = TorchEnv(gym.make(environment), transforms=pipeline)\n",
    "    s = env.reset()    \n",
    "    s_prime, r, terminated = env.step(a)\n",
    "    s_prime = torch.cat([s, s_prime])[-4:]\n",
    "    assert s_prime.dtype == torch.uint8\n",
    "\n",
    "test_should_assign_state_with_uint8_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "2e7b660f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.009 MB uploaded\\r'), FloatProgress(value=0.10711586221790304, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>epsilon</td><td>█▆▃▁</td></tr><tr><td>reward</td><td>▁█▃█</td></tr><tr><td>step</td><td>█▄▁█</td></tr><tr><td>step_loss</td><td>█▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>epsilon</td><td>0.99636</td></tr><tr><td>reward</td><td>1.5283</td></tr><tr><td>step</td><td>10160</td></tr><tr><td>step_loss</td><td>0.00035</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comfy-armadillo-5</strong> at: <a href='https://wandb.ai/garethmd/atari/runs/1zvxlry0' target=\"_blank\">https://wandb.ai/garethmd/atari/runs/1zvxlry0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240119_171245-1zvxlry0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "95b6fcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1331, 3.1186, 3.1245, 3.1267]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1724, 3.1563, 3.1611, 3.1671]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1482, 3.1338, 3.1381, 3.1462]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1731, 3.1577, 3.1627, 3.1705]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1512, 3.1224, 3.1316, 3.1465]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0785, 3.0421, 3.0541, 3.0791]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2077, 3.1701, 3.1721, 3.2142]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3163, 3.2706, 3.2784, 3.3198]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3963, 3.3538, 3.3632, 3.3897]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3996, 3.3793, 3.3913, 3.3810]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2257, 3.2033, 3.2087, 3.2306]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2619, 3.2486, 3.2538, 3.2515]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2966, 3.2778, 3.2878, 3.2812]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4176, 3.3954, 3.4062, 3.3914]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2865, 3.2565, 3.3079, 3.2648]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2691, 3.1057, 3.1680, 3.4259]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3632, 3.3417, 3.3470, 3.3574]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5937, 3.5690, 3.5749, 3.5815]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6430, 3.6125, 3.6316, 3.5947]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6828, 3.6532, 3.6666, 3.6379]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6698, 3.6398, 3.6647, 3.6246]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7059, 3.6787, 3.7043, 3.6689]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6446, 3.6332, 3.6558, 3.6289]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5559, 3.5410, 3.5738, 3.5263]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6105, 3.6023, 3.6180, 3.5819]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5544, 3.5451, 3.5536, 3.5541]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5526, 3.5507, 3.5630, 3.5567]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5157, 3.5157, 3.5353, 3.5243]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4962, 3.4781, 3.4906, 3.5012]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6306, 3.6206, 3.6226, 3.6458]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6931, 3.6850, 3.6961, 3.6984]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6339, 3.6249, 3.6412, 3.6329]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7775, 3.7676, 3.7797, 3.7699]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8147, 3.7967, 3.8039, 3.8224]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7825, 3.7629, 3.7736, 3.7784]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.9079, 3.8863, 3.8927, 3.9073]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.9331, 3.9165, 3.9269, 3.9370]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.9157, 3.9049, 3.9201, 3.9175]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.9061, 3.8899, 3.8951, 3.8948]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8329, 3.7695, 3.8322, 3.7758]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7378, 3.7120, 3.7145, 3.7250]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7471, 3.7227, 3.7268, 3.7369]], grad_fn=<AddmmBackward0>)\n",
      "tensor(1.)\n",
      "tensor([[3.0345, 3.0253, 3.0239, 3.0247]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8665, 2.8701, 2.8738, 2.8547]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9243, 2.9177, 2.9252, 2.9275]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8816, 2.8709, 2.8833, 2.8778]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9024, 2.8915, 2.8998, 2.9014]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0026, 2.9964, 3.0064, 2.9947]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9747, 2.9668, 2.9742, 2.9741]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0216, 3.0139, 3.0190, 3.0253]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0075, 2.9976, 3.0073, 3.0025]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9805, 2.9672, 2.9784, 2.9862]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0498, 3.0393, 3.0483, 3.0482]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9824, 2.9751, 2.9798, 2.9898]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1331, 3.1161, 3.1227, 3.1451]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0950, 3.0732, 3.0796, 3.0957]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3216, 3.3093, 3.3131, 3.3151]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2528, 3.2360, 3.2379, 3.2503]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2305, 3.2121, 3.2181, 3.2188]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2319, 3.2116, 3.2215, 3.2147]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3430, 3.3240, 3.3307, 3.3306]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3684, 3.3418, 3.3514, 3.3483]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3966, 3.3797, 3.3867, 3.3778]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3600, 3.3425, 3.3508, 3.3396]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2869, 3.2734, 3.2849, 3.2576]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3147, 3.2870, 3.3023, 3.2799]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3463, 3.3082, 3.3253, 3.3058]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4233, 3.4047, 3.4152, 3.3938]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3798, 3.3520, 3.3685, 3.3437]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3056, 3.2882, 3.3045, 3.2751]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5248, 3.4827, 3.5060, 3.4772]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4190, 3.3486, 3.3831, 3.3740]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4285, 3.3928, 3.4169, 3.3825]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4894, 3.4063, 3.4529, 3.4225]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4890, 3.4574, 3.4748, 3.4493]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6566, 3.6092, 3.6316, 3.6075]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6717, 3.6112, 3.6395, 3.6261]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8050, 3.7832, 3.7845, 3.7767]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7237, 3.7271, 3.7526, 3.6979]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3284, 3.3480, 3.4013, 3.3102]], grad_fn=<AddmmBackward0>)\n",
      "tensor(1.)\n",
      "tensor([[2.7601, 2.7463, 2.7530, 2.7397]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7495, 2.7321, 2.7415, 2.7195]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8869, 2.8687, 2.8753, 2.8581]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8117, 2.7954, 2.8028, 2.7812]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7081, 2.6918, 2.7024, 2.6847]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7954, 2.7787, 2.7868, 2.7666]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7706, 2.7511, 2.7587, 2.7488]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7785, 2.7612, 2.7728, 2.7622]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7253, 2.7104, 2.7197, 2.7067]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8049, 2.7883, 2.7958, 2.7796]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9499, 2.9249, 2.9247, 2.9129]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8665, 2.8435, 2.8451, 2.8333]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8660, 2.8491, 2.8516, 2.8482]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8973, 2.8768, 2.8751, 2.8713]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9441, 2.9217, 2.9158, 2.9154]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0044, 2.9792, 2.9699, 2.9737]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9307, 2.9117, 2.9097, 2.9060]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9348, 2.9145, 2.9096, 2.9102]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9573, 2.9370, 2.9331, 2.9321]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9704, 2.9498, 2.9450, 2.9444]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9688, 2.9484, 2.9441, 2.9433]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9688, 2.9484, 2.9441, 2.9433]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9688, 2.9484, 2.9441, 2.9433]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9688, 2.9484, 2.9441, 2.9433]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9688, 2.9484, 2.9441, 2.9433]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9688, 2.9484, 2.9441, 2.9433]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9688, 2.9484, 2.9441, 2.9433]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9688, 2.9484, 2.9441, 2.9433]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9688, 2.9484, 2.9441, 2.9433]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9688, 2.9484, 2.9441, 2.9433]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0523, 3.0312, 3.0427, 3.0329]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1027, 3.0728, 3.0961, 3.0738]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0881, 3.0662, 3.0768, 3.0731]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1304, 3.1084, 3.1195, 3.1152]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0622, 3.0271, 3.0423, 3.0486]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9826, 2.9412, 2.9578, 2.9696]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0519, 2.9973, 3.0127, 3.0476]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0736, 3.0119, 3.0287, 3.0686]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0884, 3.0294, 3.0489, 3.0976]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1113, 3.0603, 3.0812, 3.1002]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1084, 3.0713, 3.0898, 3.0998]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9857, 2.9621, 2.9717, 2.9742]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9272, 2.9056, 2.9178, 2.9261]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9571, 2.9386, 2.9479, 2.9596]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2007, 3.1807, 3.1884, 3.1906]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0817, 3.0188, 3.0455, 3.0439]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4020, 3.3718, 3.3835, 3.3714]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3305, 3.2419, 3.2977, 3.2462]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4583, 3.4005, 3.4337, 3.3933]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5288, 3.5072, 3.5133, 3.4983]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6232, 3.5614, 3.6195, 3.5432]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5546, 3.5011, 3.5210, 3.5034]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4584, 3.3733, 3.4167, 3.3778]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3805, 3.3328, 3.3573, 3.3450]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5378, 3.5207, 3.5457, 3.4844]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4063, 3.3901, 3.4075, 3.3724]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5820, 3.5639, 3.5706, 3.5544]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6511, 3.6210, 3.6355, 3.6039]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5673, 3.5483, 3.5654, 3.5193]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5194, 3.5085, 3.5211, 3.4875]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5236, 3.5135, 3.5275, 3.4844]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5714, 3.5489, 3.5552, 3.5463]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6727, 3.6579, 3.6709, 3.6502]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4855, 3.4573, 3.4722, 3.4447]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5132, 3.4986, 3.5040, 3.4926]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5127, 3.4837, 3.4872, 3.4900]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4817, 3.4445, 3.4460, 3.4619]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3819, 3.3035, 3.3219, 3.3619]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6261, 3.4970, 3.5366, 3.6367]], grad_fn=<AddmmBackward0>)\n",
      "tensor(1.)\n",
      "tensor([[2.6963, 2.6751, 2.6829, 2.7204]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.6028, 2.5588, 2.5603, 2.6063]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9547, 2.8678, 2.9650, 2.9597]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.6563, 2.6311, 2.6568, 2.6535]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8197, 2.7608, 2.8216, 2.8129]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.6519, 2.6439, 2.6517, 2.6612]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.6608, 2.6528, 2.6605, 2.6702]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8820, 2.8740, 2.8812, 2.8828]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8075, 2.8015, 2.8121, 2.8023]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8397, 2.8131, 2.8382, 2.8466]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7705, 2.7570, 2.7716, 2.7786]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8316, 2.8174, 2.8260, 2.8293]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8619, 2.8545, 2.8613, 2.8727]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9375, 2.9348, 2.9375, 2.9532]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8532, 2.8538, 2.8533, 2.8716]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8164, 2.8073, 2.8109, 2.8181]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8869, 2.8754, 2.8785, 2.8791]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8842, 2.8706, 2.8754, 2.8710]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9764, 2.9614, 2.9680, 2.9704]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0044, 2.9579, 2.9998, 2.9986]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9267, 2.9114, 2.9190, 2.9236]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0110, 2.9944, 3.0015, 3.0064]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1476, 3.1290, 3.1346, 3.1401]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2195, 3.2017, 3.2063, 3.2089]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4929, 3.4585, 3.4676, 3.4514]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3814, 3.3563, 3.3741, 3.3374]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3303, 3.3070, 3.3269, 3.2917]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4021, 3.3860, 3.3950, 3.3812]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4436, 3.4166, 3.4250, 3.4119]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4489, 3.4204, 3.4251, 3.4261]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4829, 3.4618, 3.4665, 3.4731]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5222, 3.5099, 3.5183, 3.5142]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4299, 3.4147, 3.4195, 3.4174]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4278, 3.4059, 3.4149, 3.4069]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4791, 3.4633, 3.4728, 3.4608]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5993, 3.5905, 3.6058, 3.5782]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4930, 3.4854, 3.5051, 3.4724]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5347, 3.5314, 3.5490, 3.5216]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6744, 3.6685, 3.6850, 3.6670]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6988, 3.6894, 3.7032, 3.6912]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6496, 3.6333, 3.6452, 3.6579]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6684, 3.6522, 3.6623, 3.6683]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5585, 3.5250, 3.5589, 3.5281]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3982, 3.3234, 3.4006, 3.3411]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4773, 3.4567, 3.4584, 3.4726]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7690, 3.7411, 3.7442, 3.7486]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3176, 3.3042, 3.3062, 3.3152]], grad_fn=<AddmmBackward0>)\n",
      "tensor(1.)\n",
      "tensor([[2.7030, 2.6988, 2.7070, 2.7106]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.5926, 2.5949, 2.6054, 2.5873]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3739, 3.2651, 3.3721, 3.3640]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0871, 3.0256, 3.0751, 3.0862]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9980, 2.9684, 2.9726, 2.9930]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0524, 3.0340, 3.0399, 3.0469]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9341, 2.9201, 2.9257, 2.9355]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2165, 3.1730, 3.2033, 3.2093]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1131, 3.0871, 3.0903, 3.1112]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0650, 3.0184, 3.0487, 3.0628]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9620, 2.9442, 2.9501, 2.9599]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0335, 3.0144, 3.0191, 3.0315]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9353, 2.8852, 2.9020, 2.9210]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9961, 2.9699, 2.9769, 2.9944]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9391, 2.8845, 2.9049, 2.9316]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0025, 2.9399, 2.9487, 2.9945]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3304, 3.2259, 3.2549, 3.2941]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5967, 3.4718, 3.5368, 3.5569]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5407, 3.4089, 3.4880, 3.5037]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7094, 3.5435, 3.6379, 3.6616]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6999, 3.5426, 3.6353, 3.6631]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8300, 3.6549, 3.7644, 3.7911]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7579, 3.5823, 3.6939, 3.7220]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7535, 3.5595, 3.6986, 3.7162]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7391, 3.5406, 3.6831, 3.6985]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7830, 3.5630, 3.7251, 3.7426]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8059, 3.5888, 3.7399, 3.7628]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7980, 3.5806, 3.7334, 3.7575]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7963, 3.5777, 3.7321, 3.7563]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7963, 3.5777, 3.7321, 3.7563]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7963, 3.5777, 3.7321, 3.7563]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7963, 3.5777, 3.7321, 3.7563]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7963, 3.5777, 3.7321, 3.7563]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7963, 3.5777, 3.7321, 3.7563]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7963, 3.5777, 3.7321, 3.7563]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7963, 3.5777, 3.7321, 3.7563]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7963, 3.5777, 3.7321, 3.7563]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0520, 3.0123, 3.0193, 3.0417]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0813, 3.0360, 3.0436, 3.0710]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0172, 2.9574, 2.9717, 3.0061]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0038, 2.9286, 2.9499, 2.9883]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9644, 2.8748, 2.9004, 2.9474]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9321, 2.8328, 2.8616, 2.9149]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9651, 2.8555, 2.8824, 2.9524]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0442, 2.9251, 2.9443, 3.0207]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1951, 3.0487, 3.0717, 3.1533]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1708, 3.0271, 3.0482, 3.1259]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1960, 3.0759, 3.1062, 3.1510]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3961, 3.2491, 3.3200, 3.3537]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4085, 3.2447, 3.3364, 3.3706]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6168, 3.4279, 3.5365, 3.5697]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6302, 3.4353, 3.5593, 3.5886]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7952, 3.5753, 3.7262, 3.7513]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8046, 3.5885, 3.7379, 3.7593]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7750, 3.5606, 3.7095, 3.7322]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7900, 3.5752, 3.7255, 3.7492]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7927, 3.5750, 3.7286, 3.7526]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7963, 3.5777, 3.7321, 3.7563]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7963, 3.5777, 3.7321, 3.7563]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7963, 3.5777, 3.7321, 3.7563]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7963, 3.5777, 3.7321, 3.7563]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8737, 2.8661, 2.8773, 2.8634]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1236, 3.0538, 3.1193, 3.1094]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0642, 3.0317, 3.0628, 3.0445]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9604, 2.9513, 2.9619, 2.9479]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0366, 3.0033, 3.0339, 3.0244]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2271, 3.1326, 3.2178, 3.2104]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1326, 3.0509, 3.1175, 3.1110]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0638, 3.0080, 3.0549, 3.0443]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2456, 3.1498, 3.2230, 3.2221]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2399, 3.1632, 3.2213, 3.2189]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1373, 3.0672, 3.1035, 3.1095]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1827, 3.1009, 3.1470, 3.1535]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0869, 3.0203, 3.0472, 3.0522]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1596, 3.0978, 3.1271, 3.1195]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2726, 3.1998, 3.2343, 3.2297]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2832, 3.2067, 3.2449, 3.2366]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2580, 3.1866, 3.2118, 3.2207]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2483, 3.1863, 3.2056, 3.2251]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3007, 3.2560, 3.2727, 3.2819]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2413, 3.1956, 3.2050, 3.2382]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1750, 3.1072, 3.1248, 3.1666]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1859, 3.1100, 3.1305, 3.1668]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1162, 3.0378, 3.0624, 3.1145]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0556, 2.9816, 3.0064, 3.0590]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2719, 3.2079, 3.2304, 3.2504]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3547, 3.3004, 3.3240, 3.3257]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3101, 3.2468, 3.2692, 3.2873]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2386, 3.1736, 3.1948, 3.2180]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4042, 3.3423, 3.3624, 3.3756]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3869, 3.3113, 3.3330, 3.3573]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4411, 3.3642, 3.3882, 3.4100]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5572, 3.4834, 3.5037, 3.5175]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6240, 3.5603, 3.5754, 3.5801]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6543, 3.5924, 3.6051, 3.6049]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6234, 3.5773, 3.5768, 3.6148]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8174, 3.7677, 3.7592, 3.8136]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7624, 3.7197, 3.7188, 3.7448]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.9259, 3.8646, 3.8872, 3.9068]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[4.0354, 3.9524, 3.9936, 4.0179]], grad_fn=<AddmmBackward0>)\n",
      "tensor(1.)\n",
      "tensor([[2.9572, 2.8729, 2.9462, 2.9370]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8626, 2.7944, 2.8521, 2.8540]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.5169, 2.4954, 2.5021, 2.5253]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.6811, 2.6114, 2.6439, 2.6741]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.6903, 2.6486, 2.6916, 2.6882]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8489, 2.7371, 2.8399, 2.8452]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7987, 2.7492, 2.7846, 2.7897]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8014, 2.7451, 2.7714, 2.7996]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7224, 2.6475, 2.6793, 2.7220]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.6780, 2.6311, 2.6427, 2.6841]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9837, 2.8711, 2.9701, 2.9909]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9142, 2.8364, 2.8945, 2.9160]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0679, 2.9604, 3.0598, 3.0622]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0033, 2.9174, 2.9940, 2.9958]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9874, 2.9463, 2.9632, 2.9760]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9749, 2.9511, 2.9636, 2.9538]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9869, 2.9667, 2.9764, 2.9736]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8143, 2.8008, 2.8416, 2.8341]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.6842, 2.6492, 2.6902, 2.7113]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9965, 2.8985, 3.0128, 3.0000]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9238, 2.8280, 2.9404, 2.9428]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1852, 3.0453, 3.1723, 3.1821]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2765, 3.1082, 3.2643, 3.2604]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2872, 3.1150, 3.2543, 3.2626]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2918, 3.1283, 3.2622, 3.2664]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2485, 3.0853, 3.2162, 3.2228]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2234, 3.0688, 3.1931, 3.1988]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0681, 3.1920, 3.1977]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2222, 3.0682, 3.1919, 3.1978]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8638, 2.8261, 2.8350, 2.8418]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9032, 2.8639, 2.8716, 2.8822]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8483, 2.7983, 2.8111, 2.8274]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8349, 2.7695, 2.7892, 2.8096]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7821, 2.7036, 2.7284, 2.7571]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7320, 2.6458, 2.6728, 2.7109]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7650, 2.6685, 2.6936, 2.7484]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7337, 2.6369, 2.6630, 2.7169]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7224, 2.6226, 2.6539, 2.7244]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8428, 2.7499, 2.7819, 2.8410]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8277, 2.7652, 2.7909, 2.8239]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7847, 2.7319, 2.7531, 2.7850]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7361, 2.6826, 2.7067, 2.7232]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.8877, 2.8094, 2.8401, 2.8575]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9273, 2.8726, 2.8933, 2.9014]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.9085, 2.7291, 2.7931, 3.0039]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3111, 3.1987, 3.2361, 3.2361]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3012, 3.2071, 3.2357, 3.2418]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3512, 3.2704, 3.2896, 3.3014]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4540, 3.4002, 3.4123, 3.4028]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5681, 3.5110, 3.5315, 3.5223]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4840, 3.4063, 3.4300, 3.4305]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4526, 3.3606, 3.3974, 3.3698]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4413, 3.3483, 3.3756, 3.3778]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5042, 3.4107, 3.4434, 3.4385]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6339, 3.6070, 3.6207, 3.5840]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6097, 3.5753, 3.5882, 3.5563]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7598, 3.7235, 3.7421, 3.6880]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8031, 3.7570, 3.7635, 3.7489]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8204, 3.7990, 3.8144, 3.7675]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7165, 3.6815, 3.6931, 3.6577]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8496, 3.8117, 3.8159, 3.8071]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8603, 3.8307, 3.8418, 3.8095]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6146, 3.5848, 3.6004, 3.5460]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6766, 3.6474, 3.6537, 3.6409]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6231, 3.5649, 3.5656, 3.5774]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.9557, 3.8469, 3.9066, 3.9185]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8183, 3.7489, 3.7546, 3.7883]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5199, 3.4733, 3.4790, 3.5456]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[4.2401, 4.1447, 4.1923, 4.1402]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7971, 3.7407, 3.7548, 3.7620]], grad_fn=<AddmmBackward0>)\n",
      "tensor(1.)\n",
      "tensor([[2.9100, 2.8891, 2.8967, 2.9102]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[2.7922, 2.6682, 2.6686, 2.7279]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1669, 3.1453, 3.1558, 3.1430]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0574, 3.0458, 3.0610, 3.0251]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2101, 3.1757, 3.1796, 3.1614]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5854, 3.4419, 3.5399, 3.5342]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0443, 3.0195, 3.0321, 3.0143]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.0967, 3.0773, 3.0901, 3.0669]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.1145, 3.0899, 3.1037, 3.0788]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2148, 3.1806, 3.1871, 3.1742]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2319, 3.1866, 3.1879, 3.1904]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4418, 3.3973, 3.3889, 3.3961]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4837, 3.4053, 3.3902, 3.4190]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3497, 3.3090, 3.3079, 3.3036]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4457, 3.3466, 3.3416, 3.3730]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2693, 3.1468, 3.1576, 3.2087]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4016, 3.3072, 3.3087, 3.3431]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3929, 3.2998, 3.3082, 3.3394]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4527, 3.3586, 3.3653, 3.3918]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.4386, 3.3457, 3.3469, 3.3975]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.2283, 3.1691, 3.1954, 3.2154]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3912, 3.3047, 3.3116, 3.3336]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5341, 3.4473, 3.4456, 3.4691]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5788, 3.4903, 3.4815, 3.5144]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7791, 3.6430, 3.6793, 3.7289]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7580, 3.5804, 3.6830, 3.7845]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8519, 3.6635, 3.7735, 3.7863]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7971, 3.6668, 3.7344, 3.7421]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.3788, 3.2577, 3.2934, 3.3058]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5207, 3.4385, 3.4581, 3.4664]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5139, 3.4146, 3.4404, 3.4506]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.7047, 3.6368, 3.6555, 3.6495]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6862, 3.5969, 3.6282, 3.6290]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8999, 3.7957, 3.8264, 3.8220]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6970, 3.5720, 3.6107, 3.6192]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.6953, 3.6238, 3.6457, 3.6406]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.9586, 3.9024, 3.9221, 3.8937]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5905, 3.5205, 3.5451, 3.5366]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.5395, 3.4909, 3.5046, 3.4870]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.9338, 3.8707, 3.8848, 3.8639]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[4.0710, 4.0225, 4.0298, 4.0121]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8621, 3.8134, 3.8226, 3.8155]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8482, 3.8090, 3.8182, 3.7902]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.9881, 3.9540, 3.9610, 3.9354]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[4.0795, 4.0268, 4.0326, 4.0208]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8341, 3.7961, 3.8126, 3.7728]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.9426, 3.8849, 3.8868, 3.8971]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.8230, 3.7339, 3.7328, 3.7642]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[3.9358, 3.8880, 3.9122, 3.8853]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[4.1833, 4.1705, 4.1849, 4.2153]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[7.3946, 6.7433, 6.9481, 7.5527]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[4.7362, 4.7415, 4.7299, 4.9606]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[4.9434, 4.8504, 4.9431, 5.0868]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[5.4397, 5.1801, 5.3212, 5.5139]], grad_fn=<AddmmBackward0>)\n",
      "tensor(4.)\n",
      "tensor([[1.9446, 1.9514, 1.9667, 1.9697]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.3931, 1.4326, 1.4484, 1.4783]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.5519, 1.5752, 1.5915, 1.6085]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.4721, 1.4707, 1.4887, 1.4951]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.4342, 1.4332, 1.4544, 1.4479]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.4886, 1.4824, 1.5055, 1.4949]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.5507, 1.5388, 1.5604, 1.5589]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.4221, 1.4263, 1.4452, 1.4490]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.3878, 1.3794, 1.4006, 1.3943]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.4834, 1.4763, 1.4959, 1.4956]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.5021, 1.4982, 1.5157, 1.5248]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.3279, 1.3356, 1.3528, 1.3686]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.3435, 1.3518, 1.3707, 1.3750]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.3997, 1.4074, 1.4233, 1.4437]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.3807, 1.3816, 1.3963, 1.4227]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.4278, 1.4366, 1.4523, 1.4716]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.3607, 1.3609, 1.3793, 1.3986]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.3073, 1.3197, 1.3413, 1.3445]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.3664, 1.3723, 1.3907, 1.3987]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.3965, 1.4032, 1.4201, 1.4342]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.3621, 1.3749, 1.3907, 1.4136]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.5439, 1.5579, 1.5731, 1.5918]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.4399, 1.4498, 1.4640, 1.4913]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.5757, 1.5803, 1.5924, 1.6223]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.5738, 1.5792, 1.5913, 1.6228]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.5927, 1.5933, 1.6056, 1.6350]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.4557, 1.4729, 1.4875, 1.5152]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.4319, 1.4498, 1.4646, 1.4911]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.3207, 1.3466, 1.3635, 1.3859]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.3328, 1.3591, 1.3758, 1.3987]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.2883, 1.3159, 1.3334, 1.3545]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.2909, 1.3184, 1.3358, 1.3570]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.2909, 1.3184, 1.3358, 1.3570]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.2909, 1.3184, 1.3358, 1.3570]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.)\n",
      "tensor([[1.2909, 1.3184, 1.3358, 1.3570]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a_zero_count = 0\n",
    "s = env.reset(seed=42)\n",
    "Q = dqn(s.permute(2, 0, 1).unsqueeze(0))\n",
    "print(Q)\n",
    "a = Q.argmax().item()\n",
    "terminated = False\n",
    "while terminated==False:\n",
    "    s_prime, r, terminated =  env.step(a)\n",
    "    print(r)\n",
    "    s_prime = preprocess(s_prime)\n",
    "    s_prime = torch.cat([s, s_prime.unsqueeze(2)], 2)[:, :, -4:]\n",
    "    s = s_prime\n",
    "    Q = dqn(s.permute(2, 0, 1).unsqueeze(0))\n",
    "    a = Q.argmax().item()\n",
    "    \n",
    "    \n",
    "    print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe5aa7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "s = env.reset(seed=42)\n",
    "terminated=False\n",
    "while terminated == False:\n",
    "    a = dqn.select_next_action(s.permute(2, 0, 1).unsqueeze(0).float(), 0.1)\n",
    "    s_prime, r, terminated = env.step(a)\n",
    "    images.append(s_prime.clone().long().numpy())\n",
    "    s_prime = preprocess(s_prime)\n",
    "    s_prime = torch.cat([s, s_prime.unsqueeze(2)], 2)[:, :, -4:]\n",
    "    s = s_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7264e417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "WRITERS[\"opencv\"](iter(images), \"test.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77e9996b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl (55.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in ./docker/predict/venv/lib/python3.8/site-packages (from opencv-python) (1.23.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "242269a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Iterator, Literal, Optional\n",
    "\n",
    "import cv2\n",
    "import ffmpeg\n",
    "import matplotlib.animation as ani\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def as_uint8(arr: np.ndarray) -> np.ndarray:\n",
    "    if np.issubdtype(arr.dtype, np.integer):\n",
    "        return arr.astype(np.uint8)\n",
    "    if np.issubdtype(arr.dtype, np.floating):\n",
    "        return (arr * 255).round().astype(np.uint8)\n",
    "    raise NotImplementedError(f\"Unsupported dtype: {arr.dtype}\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class VideoProps:\n",
    "    frame_width: int\n",
    "    frame_height: int\n",
    "    frame_count: int\n",
    "    fps: int\n",
    "\n",
    "    @classmethod\n",
    "    def from_file_opencv(cls, fpath: str) -> \"VideoProps\":\n",
    "        cap = cv2.VideoCapture(str(fpath))\n",
    "\n",
    "        return cls(\n",
    "            frame_width=int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            frame_height=int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "            frame_count=int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
    "            fps=int(cap.get(cv2.CAP_PROP_FPS)),\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_file_ffmpeg(cls, fpath: str) -> \"VideoProps\":\n",
    "        probe = ffmpeg.probe(str(fpath))\n",
    "\n",
    "        for stream in probe[\"streams\"]:\n",
    "            if stream[\"codec_type\"] == \"video\":\n",
    "                width, height, count = stream[\"width\"], stream[\"height\"], int(stream[\"nb_frames\"])\n",
    "                fps_num, fps_denom = stream[\"r_frame_rate\"].split(\"/\")\n",
    "                assert fps_denom == \"1\", f\"Unexpected frame rate: {stream['r_frame_rate']}\"\n",
    "                fps = int(fps_num)\n",
    "                return cls(\n",
    "                    frame_width=width,\n",
    "                    frame_height=height,\n",
    "                    frame_count=count,\n",
    "                    fps=fps,\n",
    "                )\n",
    "\n",
    "        raise ValueError(f\"Could not parse video properties from video in {fpath}\")\n",
    "\n",
    "\n",
    "def read_video_ffmpeg(\n",
    "    in_file: str,\n",
    "    output_fmt: str = \"rgb24\",\n",
    "    channels: int = 3,\n",
    ") -> Iterator[np.ndarray]:\n",
    "    \"\"\"Function that reads a video to a stream of numpy arrays using FFMPEG.\n",
    "\n",
    "    Args:\n",
    "        in_file: The input video to read\n",
    "        output_fmt: The output image format\n",
    "        channels: Number of output channels for each video frame\n",
    "\n",
    "    Yields:\n",
    "        Frames from the video as numpy arrays with shape (H, W, C)\n",
    "    \"\"\"\n",
    "\n",
    "    props = VideoProps.from_file_ffmpeg(in_file)\n",
    "\n",
    "    stream = ffmpeg.input(str(in_file))\n",
    "    stream = ffmpeg.output(stream, \"pipe:\", format=\"rawvideo\", pix_fmt=output_fmt, r=props.fps)\n",
    "    stream = ffmpeg.run_async(stream, pipe_stdout=True)\n",
    "\n",
    "    while True:\n",
    "        in_bytes = stream.stdout.read(props.frame_width * props.frame_height * channels)\n",
    "        if not in_bytes:\n",
    "            break\n",
    "        yield np.frombuffer(in_bytes, np.uint8).reshape((props.frame_height, props.frame_width, channels))\n",
    "\n",
    "    stream.stdout.close()\n",
    "    stream.wait()\n",
    "\n",
    "\n",
    "def read_video_opencv(in_file: str) -> Iterator[np.ndarray]:\n",
    "    \"\"\"Reads a video as a stream using OpenCV.\n",
    "\n",
    "    Args:\n",
    "        in_file: The input video to read\n",
    "\n",
    "    Yields:\n",
    "        Frames from the video as numpy arrays with shape (H, W, C)\n",
    "    \"\"\"\n",
    "\n",
    "    cap = cv2.VideoCapture(str(in_file))\n",
    "\n",
    "    while True:\n",
    "        ret, buffer = cap.read()\n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            return\n",
    "        yield buffer\n",
    "\n",
    "\n",
    "def write_video_opencv(\n",
    "    itr: Iterator[np.ndarray],\n",
    "    out_file: str,\n",
    "    fps: int = 30,\n",
    "    codec: str = \"MP4V\",\n",
    ") -> None:\n",
    "    \"\"\"Function that writes a video from a stream of numpy arrays using OpenCV.\n",
    "\n",
    "    Args:\n",
    "        itr: The image iterator, yielding images with shape (H, W, C).\n",
    "        out_file: The path to the output file.\n",
    "        fps: Frames per second for the video.\n",
    "        codec: FourCC code specifying OpenCV video codec type. Examples are\n",
    "            MPEG, MP4V, DIVX, AVC1, H236.\n",
    "    \"\"\"\n",
    "\n",
    "    first_img = next(itr)\n",
    "    height, width, _ = first_img.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "    stream = cv2.VideoWriter(str(out_file), fourcc, fps, (width, height))\n",
    "\n",
    "    def write_frame(img: np.ndarray) -> None:\n",
    "        stream.write(as_uint8(img))\n",
    "\n",
    "    write_frame(first_img)\n",
    "    for img in itr:\n",
    "        write_frame(img)\n",
    "\n",
    "    stream.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def write_video_ffmpeg(\n",
    "    itr: Iterator[np.ndarray],\n",
    "    out_file: str,\n",
    "    fps: int = 30,\n",
    "    out_fps: int = 30,\n",
    "    vcodec: str = \"libx264\",\n",
    "    input_fmt: str = \"rgb24\",\n",
    "    output_fmt: str = \"yuv420p\",\n",
    ") -> None:\n",
    "    \"\"\"Function that writes an video from a stream of numpy arrays using FFMPEG.\n",
    "\n",
    "    Args:\n",
    "        itr: The image iterator, yielding images with shape (H, W, C).\n",
    "        out_file: The path to the output file.\n",
    "        fps: Frames per second for the video.\n",
    "        out_fps: Frames per second for the saved video.\n",
    "        vcodec: The video codec to use for the output video\n",
    "        input_fmt: The input image format\n",
    "        output_fmt: The output image format\n",
    "    \"\"\"\n",
    "\n",
    "    first_img = next(itr)\n",
    "    height, width, _ = first_img.shape\n",
    "\n",
    "    stream = ffmpeg.input(\"pipe:\", format=\"rawvideo\", pix_fmt=input_fmt, s=f\"{width}x{height}\", r=fps)\n",
    "    stream = ffmpeg.output(stream, str(out_file), pix_fmt=output_fmt, vcodec=vcodec, r=out_fps)\n",
    "    stream = ffmpeg.overwrite_output(stream)\n",
    "    stream = ffmpeg.run_async(stream, pipe_stdin=True)\n",
    "\n",
    "    def write_frame(img: np.ndarray) -> None:\n",
    "        stream.stdin.write(as_uint8(img).tobytes())\n",
    "\n",
    "    # Writes all the video frames to the file.\n",
    "    write_frame(first_img)\n",
    "    for img in itr:\n",
    "        write_frame(img)\n",
    "\n",
    "    stream.stdin.close()\n",
    "    stream.wait()\n",
    "\n",
    "\n",
    "def write_video_matplotlib(\n",
    "    itr: Iterator[np.ndarray],\n",
    "    out_file: str,\n",
    "    dpi: int = 50,\n",
    "    fps: int = 30,\n",
    "    title: str = \"Video\",\n",
    "    comment: Optional[str] = None,\n",
    "    writer: str = \"ffmpeg\",\n",
    ") -> None:\n",
    "    \"\"\"Function that writes an video from a stream of input tensors.\n",
    "\n",
    "    Args:\n",
    "        itr: The image iterator, yielding images with shape (H, W, C).\n",
    "        out_file: The path to the output file.\n",
    "        dpi: Dots per inch for output image.\n",
    "        fps: Frames per second for the video.\n",
    "        title: Title for the video metadata.\n",
    "        comment: Comment for the video metadata.\n",
    "        writer: The Matplotlib video writer to use (if you use the\n",
    "            default one, make sure you have `ffmpeg` installed on your\n",
    "            system).\n",
    "    \"\"\"\n",
    "\n",
    "    first_img = next(itr)\n",
    "    height, width, _ = first_img.shape\n",
    "    fig, ax = plt.subplots(figsize=(width / dpi, height / dpi))\n",
    "\n",
    "    # Ensures that there's no extra space around the image.\n",
    "    fig.subplots_adjust(\n",
    "        left=0,\n",
    "        bottom=0,\n",
    "        right=1,\n",
    "        top=1,\n",
    "        wspace=None,\n",
    "        hspace=None,\n",
    "    )\n",
    "\n",
    "    # Creates the writer with the given metadata.\n",
    "    writer_obj = ani.writers[writer]\n",
    "    metadata = {\n",
    "        \"title\": title,\n",
    "        \"artist\": __name__,\n",
    "        \"comment\": comment,\n",
    "    }\n",
    "    mpl_writer = writer_obj(\n",
    "        fps=fps,\n",
    "        metadata={k: v for k, v in metadata.items() if v is not None},\n",
    "    )\n",
    "\n",
    "    with mpl_writer.saving(fig, out_file, dpi=dpi):\n",
    "        im = ax.imshow(as_uint8(first_img), interpolation=\"nearest\")\n",
    "        mpl_writer.grab_frame()\n",
    "\n",
    "        for img in itr:\n",
    "            im.set_data(as_uint8(img))\n",
    "            mpl_writer.grab_frame()\n",
    "\n",
    "\n",
    "Reader = Literal[\"ffmpeg\", \"opencv\"]\n",
    "Writer = Literal[\"ffmpeg\", \"matplotlib\", \"opencv\"]\n",
    "\n",
    "READERS: Dict[Reader, Callable[[str], Iterator[np.ndarray]]] = {\n",
    "    \"ffmpeg\": read_video_ffmpeg,\n",
    "    \"opencv\": read_video_opencv,\n",
    "}\n",
    "\n",
    "WRITERS: Dict[Writer, Callable[[Iterator[np.ndarray], str], None]] = {\n",
    "    \"ffmpeg\": write_video_ffmpeg,\n",
    "    \"matplotlib\": write_video_matplotlib,\n",
    "    \"opencv\": write_video_opencv,\n",
    "}\n",
    "\n",
    "# Remove the FFMPEG reader and writer if FFMPEG is not available in the system.\n",
    "if not shutil.which(\"ffmpeg\"):\n",
    "    READERS.pop(\"ffmpeg\")\n",
    "    WRITERS.pop(\"ffmpeg\")\n",
    "    WRITERS.pop(\"matplotlib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5aa46a",
   "metadata": {
    "id": "1c5aa46a"
   },
   "source": [
    "## Improve Performance Efficiency\n",
    "An issue we are facing is that the code currently makes multiple forward passes through the network as we are fetching values for each individual training example. This makes the code easier to understand but very slow to run. We will change that so that batches of data will be passed to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74db444b",
   "metadata": {
    "id": "74db444b",
    "outputId": "ceefc037-8bca-4bc0-c0a4-5dc59b38ec8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<magic-timeit>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/var/folders/8w/2dpk8lsx6hl861tqrs31bxb80000gn/T/ipykernel_60609/583668238.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s = torch.tensor(s)\n",
      "/var/folders/8w/2dpk8lsx6hl861tqrs31bxb80000gn/T/ipykernel_60609/583668238.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s_prime = torch.tensor(s_prime)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1 episode_loss 19.43286417717536, reward 1.0, steps 196\n",
      "episode 1 episode_loss 0.08061189765794552, reward 0.0, steps 133\n",
      "episode 1 episode_loss 0.08898574351405841, reward 1.0, steps 161\n",
      "episode 1 episode_loss 0.26165696167299757, reward 2.0, steps 223\n",
      "episode 1 episode_loss 0.5946118091815151, reward 5.0, steps 300\n",
      "episode 1 episode_loss 0.23256916616810486, reward 1.0, steps 167\n",
      "episode 1 episode_loss 0.20791195419587893, reward 1.0, steps 185\n",
      "episode 1 episode_loss 0.1303796372958459, reward 0.0, steps 145\n",
      "28.3 s ± 8.7 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "N = 1000 #replay memory max size\n",
    "bs = 32\n",
    "gamma = 0.99\n",
    "epsilon = 1\n",
    "\n",
    "M = 1\n",
    "steps = 0\n",
    "for i in range(M):\n",
    "    terminated = False\n",
    "    s, info = reset(env)\n",
    "    s = torch.tensor(s)\n",
    "    episode_loss = 0\n",
    "    episode_reward = 0\n",
    "    episode_length = 0\n",
    "    while terminated == False:\n",
    "\n",
    "        a = dqn.select_next_action(s, epsilon)\n",
    "        s_prime, r, terminated, truncated, info = step(env, a)\n",
    "        s_prime = preprocess(s_prime)\n",
    "        s_prime = torch.cat([s, s_prime.unsqueeze(2)], 2)[:, :, -4:]\n",
    "        replay_memory.append((s, a, r, s_prime, terminated))\n",
    "\n",
    "        episode_reward += r.item()\n",
    "        episode_length += 1\n",
    "\n",
    "        batch = replay_memory.sample(bs)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_hat, y = get_batch(dqn, batch)\n",
    "\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        episode_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        steps += 1\n",
    "        torch.nn.utils.clip_grad_value_(dqn.parameters(), 100)\n",
    "        if epsilon > 0.05 :\n",
    "            epsilon -= (1 / 5000)\n",
    "        s = s_prime\n",
    "\n",
    "    episode_lengths.append(episode_length)\n",
    "\n",
    "    # if i % 20 == 0:\n",
    "    print(f'episode {i+1} episode_loss {episode_loss}, reward {episode_reward}, steps {steps}')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c2024",
   "metadata": {
    "id": "394c2024",
    "outputId": "14a80e64-3e2f-467b-dbf5-e549ba81ec0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184.5"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_steps_per_episode = (134 + 281 + 170 + 134 + 243 + 129 + 203 + 182)/8\n",
    "mean_steps_per_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c703d",
   "metadata": {
    "id": "718c703d"
   },
   "outputs": [],
   "source": [
    "bs = 32\n",
    "class EfficientAtariDQN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, n_actions):\n",
    "        super(EfficientAtariDQN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, 8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32*9*9, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_actions)\n",
    "        )\n",
    "        self.n_actions = n_actions\n",
    "\n",
    "    def forward(self, s):\n",
    "        return self.conv(s.float())\n",
    "\n",
    "    def select_next_action(self, s, epsilon):\n",
    "        use_greedy = np.random.binomial(1, 1-epsilon)\n",
    "        if use_greedy:\n",
    "            a = self(s).argmax().item()\n",
    "        else:\n",
    "            a = np.random.choice(self.n_actions)\n",
    "        return a\n",
    "\n",
    "dqn = EfficientAtariDQN(in_dim=env.observation_space.shape[0], hidden_dim=9, n_actions=env.action_space.n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4935c",
   "metadata": {
    "id": "99c4935c"
   },
   "outputs": [],
   "source": [
    "def atari_collate(batch):\n",
    "    s_j, a_j, r_j, s_prime_j, terminated_j = list(zip(*batch))\n",
    "    return torch.stack(s_j).permute(0, 3, 1, 2), torch.tensor(a_j), torch.tensor(r_j), torch.stack(s_prime_j).permute(0, 3, 1, 2), (~torch.tensor(terminated_j)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e45740",
   "metadata": {
    "id": "e4e45740",
    "outputId": "705ab84a-0f96-42f2-a8e2-6fe1708b9cbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 µs ± 2.02 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "batch = replay_memory.sample(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d61cf84",
   "metadata": {
    "id": "6d61cf84",
    "outputId": "08eee888-8ac0-4767-d1f5-9afb61a72f40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62500.0"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000000 / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eda7b0",
   "metadata": {
    "id": "26eda7b0",
    "outputId": "634269f0-86bb-4b9e-d435-3c913e268d4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8w/2dpk8lsx6hl861tqrs31bxb80000gn/T/ipykernel_60609/3614971170.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s = torch.tensor(s)\n",
      "/var/folders/8w/2dpk8lsx6hl861tqrs31bxb80000gn/T/ipykernel_60609/583668238.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s = torch.tensor(s)\n",
      "/var/folders/8w/2dpk8lsx6hl861tqrs31bxb80000gn/T/ipykernel_60609/583668238.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s_prime = torch.tensor(s_prime)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1 episode_loss 482.0094321966171, reward 3.0, steps 272, epoch 0.00544\n",
      "episode 101 episode_loss 322.11623126268387, reward 2.0, steps 21058, epoch 0.42116\n",
      "episode 201 episode_loss 215.76791804283857, reward 8.0, steps 48889, epoch 0.97778\n",
      "episode 301 episode_loss 119.2069219830446, reward 7.0, steps 89477, epoch 1.78954\n",
      "episode 401 episode_loss 99.53891976736486, reward 8.0, steps 134177, epoch 2.68354\n",
      "episode 501 episode_loss 60.76320995064452, reward 7.0, steps 176072, epoch 3.52144\n",
      "episode 601 episode_loss 89.25185312365647, reward 7.0, steps 219691, epoch 4.39382\n",
      "episode 701 episode_loss 63.48463975416962, reward 4.0, steps 262570, epoch 5.2514\n",
      "episode 801 episode_loss 86.89205625501927, reward 3.0, steps 305018, epoch 6.10036\n",
      "episode 901 episode_loss 104.9817000987241, reward 7.0, steps 349154, epoch 6.98308\n",
      "episode 1001 episode_loss 97.93874165776651, reward 11.0, steps 391892, epoch 7.83784\n",
      "episode 1101 episode_loss 76.31025852193125, reward 7.0, steps 434048, epoch 8.68096\n",
      "episode 1201 episode_loss 148.8159403713653, reward 7.0, steps 476821, epoch 9.53642\n",
      "episode 1301 episode_loss 69.77878785296343, reward 1.0, steps 520619, epoch 10.41238\n",
      "episode 1401 episode_loss 106.68529581662733, reward 11.0, steps 562441, epoch 11.24882\n",
      "episode 1501 episode_loss 118.52021295041777, reward 7.0, steps 606020, epoch 12.1204\n",
      "episode 1601 episode_loss 64.24022578995209, reward 7.0, steps 648801, epoch 12.97602\n",
      "episode 1701 episode_loss 112.87910554383416, reward 7.0, steps 692098, epoch 13.84196\n",
      "episode 1801 episode_loss 79.37506981205661, reward 7.0, steps 736195, epoch 14.7239\n",
      "episode 1901 episode_loss 99.0631368541508, reward 11.0, steps 778806, epoch 15.57612\n"
     ]
    }
   ],
   "source": [
    "N = 62500 #replay memory max size\n",
    "bs = 32\n",
    "gamma = 0.99\n",
    "epsilon = 1\n",
    "\n",
    "M = 2000\n",
    "steps = 0\n",
    "epoch = 1\n",
    "for i in range(M):\n",
    "    terminated = False\n",
    "    s, info = reset(env)\n",
    "    s = torch.tensor(s)\n",
    "    episode_loss = 0\n",
    "    episode_reward = 0\n",
    "    episode_length = 0\n",
    "    while terminated == False:\n",
    "\n",
    "        a = dqn.select_next_action(s.permute(2, 0, 1).unsqueeze(0), epsilon)\n",
    "        s_prime, r, terminated, truncated, info = step(env, a)\n",
    "        s_prime = preprocess(s_prime)\n",
    "        s_prime = torch.cat([s, s_prime.unsqueeze(2)], 2)[:, :, -4:]\n",
    "        replay_memory.append((s, a, r, s_prime, terminated))\n",
    "\n",
    "        episode_reward += r.item()\n",
    "        episode_length += 1\n",
    "\n",
    "        batch = replay_memory.sample(bs)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_hat, y = get_batch_efficient(dqn, batch, atari_collate)\n",
    "\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        episode_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        steps += 1\n",
    "        torch.nn.utils.clip_grad_value_(dqn.parameters(), 100)\n",
    "        epsilon = get_epsilon(epsilon)\n",
    "        s = s_prime\n",
    "\n",
    "    episode_lengths.append(episode_length)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        epoch = steps / 50000\n",
    "        print(f'episode {i+1} episode_loss {episode_loss}, reward {episode_reward}, steps {steps}, epoch {epoch}')\n",
    "        torch.save(dqn, 'breakout.pt')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9530d8",
   "metadata": {
    "id": "5c9530d8",
    "outputId": "e5bf8216-8db4-49d2-d51b-779d4d335f58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8w/2dpk8lsx6hl861tqrs31bxb80000gn/T/ipykernel_60609/4143087600.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s = torch.tensor(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 {'lives': 5, 'episode_frame_number': 16, 'frame_number': 16}\n",
      "3 {'lives': 5, 'episode_frame_number': 20, 'frame_number': 20}\n",
      "3 {'lives': 5, 'episode_frame_number': 24, 'frame_number': 24}\n",
      "3 {'lives': 5, 'episode_frame_number': 28, 'frame_number': 28}\n",
      "3 {'lives': 5, 'episode_frame_number': 32, 'frame_number': 32}\n",
      "3 {'lives': 5, 'episode_frame_number': 36, 'frame_number': 36}\n",
      "3 {'lives': 5, 'episode_frame_number': 40, 'frame_number': 40}\n",
      "3 {'lives': 5, 'episode_frame_number': 44, 'frame_number': 44}\n",
      "3 {'lives': 5, 'episode_frame_number': 48, 'frame_number': 48}\n",
      "3 {'lives': 5, 'episode_frame_number': 52, 'frame_number': 52}\n",
      "3 {'lives': 5, 'episode_frame_number': 56, 'frame_number': 56}\n",
      "3 {'lives': 5, 'episode_frame_number': 60, 'frame_number': 60}\n",
      "3 {'lives': 5, 'episode_frame_number': 64, 'frame_number': 64}\n",
      "3 {'lives': 5, 'episode_frame_number': 68, 'frame_number': 68}\n",
      "0 {'lives': 5, 'episode_frame_number': 72, 'frame_number': 72}\n",
      "3 {'lives': 5, 'episode_frame_number': 76, 'frame_number': 76}\n",
      "3 {'lives': 5, 'episode_frame_number': 80, 'frame_number': 80}\n",
      "3 {'lives': 5, 'episode_frame_number': 84, 'frame_number': 84}\n",
      "3 {'lives': 5, 'episode_frame_number': 88, 'frame_number': 88}\n",
      "3 {'lives': 5, 'episode_frame_number': 92, 'frame_number': 92}\n",
      "3 {'lives': 5, 'episode_frame_number': 96, 'frame_number': 96}\n",
      "3 {'lives': 5, 'episode_frame_number': 100, 'frame_number': 100}\n",
      "3 {'lives': 5, 'episode_frame_number': 104, 'frame_number': 104}\n",
      "3 {'lives': 5, 'episode_frame_number': 108, 'frame_number': 108}\n",
      "3 {'lives': 5, 'episode_frame_number': 112, 'frame_number': 112}\n",
      "3 {'lives': 5, 'episode_frame_number': 116, 'frame_number': 116}\n",
      "3 {'lives': 5, 'episode_frame_number': 120, 'frame_number': 120}\n",
      "3 {'lives': 5, 'episode_frame_number': 124, 'frame_number': 124}\n",
      "3 {'lives': 5, 'episode_frame_number': 128, 'frame_number': 128}\n",
      "3 {'lives': 5, 'episode_frame_number': 132, 'frame_number': 132}\n",
      "3 {'lives': 5, 'episode_frame_number': 136, 'frame_number': 136}\n",
      "3 {'lives': 5, 'episode_frame_number': 140, 'frame_number': 140}\n",
      "3 {'lives': 5, 'episode_frame_number': 144, 'frame_number': 144}\n",
      "3 {'lives': 5, 'episode_frame_number': 148, 'frame_number': 148}\n",
      "3 {'lives': 5, 'episode_frame_number': 152, 'frame_number': 152}\n",
      "3 {'lives': 5, 'episode_frame_number': 156, 'frame_number': 156}\n",
      "3 {'lives': 5, 'episode_frame_number': 160, 'frame_number': 160}\n",
      "3 {'lives': 5, 'episode_frame_number': 164, 'frame_number': 164}\n",
      "3 {'lives': 5, 'episode_frame_number': 168, 'frame_number': 168}\n",
      "3 {'lives': 5, 'episode_frame_number': 172, 'frame_number': 172}\n",
      "3 {'lives': 5, 'episode_frame_number': 176, 'frame_number': 176}\n",
      "3 {'lives': 5, 'episode_frame_number': 180, 'frame_number': 180}\n",
      "3 {'lives': 5, 'episode_frame_number': 184, 'frame_number': 184}\n",
      "3 {'lives': 5, 'episode_frame_number': 188, 'frame_number': 188}\n",
      "3 {'lives': 5, 'episode_frame_number': 192, 'frame_number': 192}\n",
      "3 {'lives': 5, 'episode_frame_number': 196, 'frame_number': 196}\n",
      "3 {'lives': 5, 'episode_frame_number': 200, 'frame_number': 200}\n",
      "3 {'lives': 5, 'episode_frame_number': 204, 'frame_number': 204}\n",
      "3 {'lives': 5, 'episode_frame_number': 208, 'frame_number': 208}\n",
      "3 {'lives': 5, 'episode_frame_number': 212, 'frame_number': 212}\n",
      "3 {'lives': 5, 'episode_frame_number': 216, 'frame_number': 216}\n",
      "3 {'lives': 5, 'episode_frame_number': 220, 'frame_number': 220}\n",
      "3 {'lives': 5, 'episode_frame_number': 224, 'frame_number': 224}\n",
      "3 {'lives': 5, 'episode_frame_number': 228, 'frame_number': 228}\n",
      "3 {'lives': 5, 'episode_frame_number': 232, 'frame_number': 232}\n",
      "3 {'lives': 5, 'episode_frame_number': 236, 'frame_number': 236}\n",
      "2 {'lives': 5, 'episode_frame_number': 240, 'frame_number': 240}\n",
      "3 {'lives': 5, 'episode_frame_number': 244, 'frame_number': 244}\n",
      "3 {'lives': 5, 'episode_frame_number': 248, 'frame_number': 248}\n",
      "3 {'lives': 5, 'episode_frame_number': 252, 'frame_number': 252}\n",
      "3 {'lives': 5, 'episode_frame_number': 256, 'frame_number': 256}\n",
      "0 {'lives': 5, 'episode_frame_number': 260, 'frame_number': 260}\n",
      "3 {'lives': 5, 'episode_frame_number': 264, 'frame_number': 264}\n",
      "3 {'lives': 5, 'episode_frame_number': 268, 'frame_number': 268}\n",
      "3 {'lives': 5, 'episode_frame_number': 272, 'frame_number': 272}\n",
      "3 {'lives': 5, 'episode_frame_number': 276, 'frame_number': 276}\n",
      "3 {'lives': 5, 'episode_frame_number': 280, 'frame_number': 280}\n",
      "3 {'lives': 5, 'episode_frame_number': 284, 'frame_number': 284}\n",
      "3 {'lives': 5, 'episode_frame_number': 288, 'frame_number': 288}\n",
      "2 {'lives': 5, 'episode_frame_number': 292, 'frame_number': 292}\n",
      "3 {'lives': 5, 'episode_frame_number': 296, 'frame_number': 296}\n",
      "3 {'lives': 5, 'episode_frame_number': 300, 'frame_number': 300}\n",
      "3 {'lives': 5, 'episode_frame_number': 304, 'frame_number': 304}\n",
      "3 {'lives': 5, 'episode_frame_number': 308, 'frame_number': 308}\n",
      "3 {'lives': 5, 'episode_frame_number': 312, 'frame_number': 312}\n",
      "3 {'lives': 5, 'episode_frame_number': 316, 'frame_number': 316}\n",
      "3 {'lives': 5, 'episode_frame_number': 320, 'frame_number': 320}\n",
      "3 {'lives': 5, 'episode_frame_number': 324, 'frame_number': 324}\n",
      "3 {'lives': 5, 'episode_frame_number': 328, 'frame_number': 328}\n",
      "3 {'lives': 5, 'episode_frame_number': 332, 'frame_number': 332}\n",
      "3 {'lives': 5, 'episode_frame_number': 336, 'frame_number': 336}\n",
      "3 {'lives': 5, 'episode_frame_number': 340, 'frame_number': 340}\n",
      "3 {'lives': 5, 'episode_frame_number': 344, 'frame_number': 344}\n",
      "3 {'lives': 5, 'episode_frame_number': 348, 'frame_number': 348}\n",
      "3 {'lives': 5, 'episode_frame_number': 352, 'frame_number': 352}\n",
      "3 {'lives': 5, 'episode_frame_number': 356, 'frame_number': 356}\n",
      "3 {'lives': 5, 'episode_frame_number': 360, 'frame_number': 360}\n",
      "3 {'lives': 5, 'episode_frame_number': 364, 'frame_number': 364}\n",
      "3 {'lives': 5, 'episode_frame_number': 368, 'frame_number': 368}\n",
      "3 {'lives': 5, 'episode_frame_number': 372, 'frame_number': 372}\n",
      "3 {'lives': 5, 'episode_frame_number': 376, 'frame_number': 376}\n",
      "3 {'lives': 5, 'episode_frame_number': 380, 'frame_number': 380}\n",
      "3 {'lives': 5, 'episode_frame_number': 384, 'frame_number': 384}\n",
      "3 {'lives': 5, 'episode_frame_number': 388, 'frame_number': 388}\n",
      "3 {'lives': 5, 'episode_frame_number': 392, 'frame_number': 392}\n",
      "3 {'lives': 5, 'episode_frame_number': 396, 'frame_number': 396}\n",
      "3 {'lives': 5, 'episode_frame_number': 400, 'frame_number': 400}\n",
      "3 {'lives': 5, 'episode_frame_number': 404, 'frame_number': 404}\n",
      "2 {'lives': 5, 'episode_frame_number': 408, 'frame_number': 408}\n",
      "3 {'lives': 5, 'episode_frame_number': 412, 'frame_number': 412}\n",
      "3 {'lives': 5, 'episode_frame_number': 416, 'frame_number': 416}\n",
      "3 {'lives': 5, 'episode_frame_number': 420, 'frame_number': 420}\n",
      "3 {'lives': 5, 'episode_frame_number': 424, 'frame_number': 424}\n",
      "3 {'lives': 5, 'episode_frame_number': 428, 'frame_number': 428}\n",
      "3 {'lives': 5, 'episode_frame_number': 432, 'frame_number': 432}\n",
      "3 {'lives': 5, 'episode_frame_number': 436, 'frame_number': 436}\n",
      "3 {'lives': 5, 'episode_frame_number': 440, 'frame_number': 440}\n",
      "3 {'lives': 5, 'episode_frame_number': 444, 'frame_number': 444}\n",
      "3 {'lives': 5, 'episode_frame_number': 448, 'frame_number': 448}\n",
      "3 {'lives': 5, 'episode_frame_number': 452, 'frame_number': 452}\n",
      "3 {'lives': 5, 'episode_frame_number': 456, 'frame_number': 456}\n",
      "3 {'lives': 5, 'episode_frame_number': 460, 'frame_number': 460}\n",
      "0 {'lives': 5, 'episode_frame_number': 464, 'frame_number': 464}\n",
      "3 {'lives': 5, 'episode_frame_number': 468, 'frame_number': 468}\n",
      "3 {'lives': 5, 'episode_frame_number': 472, 'frame_number': 472}\n",
      "3 {'lives': 5, 'episode_frame_number': 476, 'frame_number': 476}\n",
      "3 {'lives': 5, 'episode_frame_number': 480, 'frame_number': 480}\n",
      "2 {'lives': 5, 'episode_frame_number': 484, 'frame_number': 484}\n",
      "3 {'lives': 5, 'episode_frame_number': 488, 'frame_number': 488}\n",
      "3 {'lives': 5, 'episode_frame_number': 492, 'frame_number': 492}\n",
      "3 {'lives': 5, 'episode_frame_number': 496, 'frame_number': 496}\n",
      "3 {'lives': 5, 'episode_frame_number': 500, 'frame_number': 500}\n",
      "1 {'lives': 5, 'episode_frame_number': 504, 'frame_number': 504}\n",
      "3 {'lives': 5, 'episode_frame_number': 508, 'frame_number': 508}\n",
      "3 {'lives': 5, 'episode_frame_number': 512, 'frame_number': 512}\n",
      "3 {'lives': 5, 'episode_frame_number': 516, 'frame_number': 516}\n",
      "3 {'lives': 5, 'episode_frame_number': 520, 'frame_number': 520}\n",
      "3 {'lives': 5, 'episode_frame_number': 524, 'frame_number': 524}\n",
      "3 {'lives': 5, 'episode_frame_number': 528, 'frame_number': 528}\n",
      "3 {'lives': 5, 'episode_frame_number': 532, 'frame_number': 532}\n",
      "3 {'lives': 5, 'episode_frame_number': 536, 'frame_number': 536}\n",
      "3 {'lives': 5, 'episode_frame_number': 540, 'frame_number': 540}\n",
      "2 {'lives': 5, 'episode_frame_number': 544, 'frame_number': 544}\n",
      "3 {'lives': 5, 'episode_frame_number': 548, 'frame_number': 548}\n",
      "3 {'lives': 5, 'episode_frame_number': 552, 'frame_number': 552}\n",
      "3 {'lives': 5, 'episode_frame_number': 556, 'frame_number': 556}\n",
      "3 {'lives': 5, 'episode_frame_number': 560, 'frame_number': 560}\n",
      "3 {'lives': 5, 'episode_frame_number': 564, 'frame_number': 564}\n",
      "3 {'lives': 5, 'episode_frame_number': 568, 'frame_number': 568}\n",
      "3 {'lives': 5, 'episode_frame_number': 572, 'frame_number': 572}\n",
      "3 {'lives': 5, 'episode_frame_number': 576, 'frame_number': 576}\n",
      "3 {'lives': 5, 'episode_frame_number': 580, 'frame_number': 580}\n",
      "3 {'lives': 5, 'episode_frame_number': 584, 'frame_number': 584}\n",
      "3 {'lives': 5, 'episode_frame_number': 588, 'frame_number': 588}\n",
      "3 {'lives': 5, 'episode_frame_number': 592, 'frame_number': 592}\n",
      "3 {'lives': 5, 'episode_frame_number': 596, 'frame_number': 596}\n",
      "3 {'lives': 5, 'episode_frame_number': 600, 'frame_number': 600}\n",
      "0 {'lives': 5, 'episode_frame_number': 604, 'frame_number': 604}\n",
      "3 {'lives': 5, 'episode_frame_number': 608, 'frame_number': 608}\n",
      "3 {'lives': 5, 'episode_frame_number': 612, 'frame_number': 612}\n",
      "3 {'lives': 5, 'episode_frame_number': 616, 'frame_number': 616}\n",
      "3 {'lives': 5, 'episode_frame_number': 620, 'frame_number': 620}\n",
      "3 {'lives': 5, 'episode_frame_number': 624, 'frame_number': 624}\n",
      "3 {'lives': 5, 'episode_frame_number': 628, 'frame_number': 628}\n",
      "3 {'lives': 5, 'episode_frame_number': 632, 'frame_number': 632}\n",
      "3 {'lives': 5, 'episode_frame_number': 636, 'frame_number': 636}\n",
      "3 {'lives': 5, 'episode_frame_number': 640, 'frame_number': 640}\n",
      "3 {'lives': 5, 'episode_frame_number': 644, 'frame_number': 644}\n",
      "3 {'lives': 5, 'episode_frame_number': 648, 'frame_number': 648}\n",
      "3 {'lives': 5, 'episode_frame_number': 652, 'frame_number': 652}\n",
      "3 {'lives': 5, 'episode_frame_number': 656, 'frame_number': 656}\n",
      "3 {'lives': 5, 'episode_frame_number': 660, 'frame_number': 660}\n",
      "3 {'lives': 5, 'episode_frame_number': 664, 'frame_number': 664}\n",
      "3 {'lives': 5, 'episode_frame_number': 668, 'frame_number': 668}\n",
      "3 {'lives': 5, 'episode_frame_number': 672, 'frame_number': 672}\n",
      "3 {'lives': 5, 'episode_frame_number': 676, 'frame_number': 676}\n",
      "0 {'lives': 5, 'episode_frame_number': 680, 'frame_number': 680}\n",
      "3 {'lives': 5, 'episode_frame_number': 684, 'frame_number': 684}\n",
      "3 {'lives': 5, 'episode_frame_number': 688, 'frame_number': 688}\n",
      "1 {'lives': 5, 'episode_frame_number': 692, 'frame_number': 692}\n",
      "3 {'lives': 5, 'episode_frame_number': 696, 'frame_number': 696}\n",
      "3 {'lives': 5, 'episode_frame_number': 700, 'frame_number': 700}\n",
      "3 {'lives': 5, 'episode_frame_number': 704, 'frame_number': 704}\n",
      "3 {'lives': 5, 'episode_frame_number': 708, 'frame_number': 708}\n",
      "3 {'lives': 4, 'episode_frame_number': 712, 'frame_number': 712}\n",
      "3 {'lives': 4, 'episode_frame_number': 716, 'frame_number': 716}\n",
      "3 {'lives': 4, 'episode_frame_number': 720, 'frame_number': 720}\n",
      "3 {'lives': 4, 'episode_frame_number': 724, 'frame_number': 724}\n",
      "1 {'lives': 4, 'episode_frame_number': 728, 'frame_number': 728}\n",
      "3 {'lives': 4, 'episode_frame_number': 732, 'frame_number': 732}\n",
      "3 {'lives': 4, 'episode_frame_number': 736, 'frame_number': 736}\n",
      "3 {'lives': 4, 'episode_frame_number': 740, 'frame_number': 740}\n",
      "3 {'lives': 4, 'episode_frame_number': 744, 'frame_number': 744}\n",
      "3 {'lives': 4, 'episode_frame_number': 748, 'frame_number': 748}\n",
      "3 {'lives': 4, 'episode_frame_number': 752, 'frame_number': 752}\n",
      "3 {'lives': 4, 'episode_frame_number': 756, 'frame_number': 756}\n",
      "3 {'lives': 4, 'episode_frame_number': 760, 'frame_number': 760}\n",
      "3 {'lives': 4, 'episode_frame_number': 764, 'frame_number': 764}\n",
      "3 {'lives': 4, 'episode_frame_number': 768, 'frame_number': 768}\n",
      "3 {'lives': 4, 'episode_frame_number': 772, 'frame_number': 772}\n",
      "3 {'lives': 4, 'episode_frame_number': 776, 'frame_number': 776}\n",
      "3 {'lives': 4, 'episode_frame_number': 780, 'frame_number': 780}\n",
      "3 {'lives': 4, 'episode_frame_number': 784, 'frame_number': 784}\n",
      "3 {'lives': 4, 'episode_frame_number': 788, 'frame_number': 788}\n",
      "3 {'lives': 4, 'episode_frame_number': 792, 'frame_number': 792}\n",
      "3 {'lives': 4, 'episode_frame_number': 796, 'frame_number': 796}\n",
      "3 {'lives': 4, 'episode_frame_number': 800, 'frame_number': 800}\n",
      "3 {'lives': 4, 'episode_frame_number': 804, 'frame_number': 804}\n",
      "3 {'lives': 4, 'episode_frame_number': 808, 'frame_number': 808}\n",
      "3 {'lives': 4, 'episode_frame_number': 812, 'frame_number': 812}\n",
      "3 {'lives': 4, 'episode_frame_number': 816, 'frame_number': 816}\n",
      "3 {'lives': 4, 'episode_frame_number': 820, 'frame_number': 820}\n",
      "3 {'lives': 4, 'episode_frame_number': 824, 'frame_number': 824}\n",
      "3 {'lives': 4, 'episode_frame_number': 828, 'frame_number': 828}\n",
      "3 {'lives': 4, 'episode_frame_number': 832, 'frame_number': 832}\n",
      "3 {'lives': 4, 'episode_frame_number': 836, 'frame_number': 836}\n",
      "3 {'lives': 4, 'episode_frame_number': 840, 'frame_number': 840}\n",
      "3 {'lives': 4, 'episode_frame_number': 844, 'frame_number': 844}\n",
      "3 {'lives': 4, 'episode_frame_number': 848, 'frame_number': 848}\n",
      "3 {'lives': 4, 'episode_frame_number': 852, 'frame_number': 852}\n",
      "3 {'lives': 4, 'episode_frame_number': 856, 'frame_number': 856}\n",
      "3 {'lives': 4, 'episode_frame_number': 860, 'frame_number': 860}\n",
      "1 {'lives': 4, 'episode_frame_number': 864, 'frame_number': 864}\n",
      "3 {'lives': 4, 'episode_frame_number': 868, 'frame_number': 868}\n",
      "3 {'lives': 4, 'episode_frame_number': 872, 'frame_number': 872}\n",
      "3 {'lives': 4, 'episode_frame_number': 876, 'frame_number': 876}\n",
      "3 {'lives': 4, 'episode_frame_number': 880, 'frame_number': 880}\n",
      "3 {'lives': 4, 'episode_frame_number': 884, 'frame_number': 884}\n",
      "3 {'lives': 4, 'episode_frame_number': 888, 'frame_number': 888}\n",
      "3 {'lives': 4, 'episode_frame_number': 892, 'frame_number': 892}\n",
      "3 {'lives': 4, 'episode_frame_number': 896, 'frame_number': 896}\n",
      "2 {'lives': 4, 'episode_frame_number': 900, 'frame_number': 900}\n",
      "3 {'lives': 4, 'episode_frame_number': 904, 'frame_number': 904}\n",
      "3 {'lives': 4, 'episode_frame_number': 908, 'frame_number': 908}\n",
      "3 {'lives': 4, 'episode_frame_number': 912, 'frame_number': 912}\n",
      "3 {'lives': 4, 'episode_frame_number': 916, 'frame_number': 916}\n",
      "3 {'lives': 4, 'episode_frame_number': 920, 'frame_number': 920}\n",
      "3 {'lives': 4, 'episode_frame_number': 924, 'frame_number': 924}\n",
      "3 {'lives': 4, 'episode_frame_number': 928, 'frame_number': 928}\n",
      "3 {'lives': 4, 'episode_frame_number': 932, 'frame_number': 932}\n",
      "3 {'lives': 4, 'episode_frame_number': 936, 'frame_number': 936}\n",
      "3 {'lives': 4, 'episode_frame_number': 940, 'frame_number': 940}\n",
      "3 {'lives': 3, 'episode_frame_number': 944, 'frame_number': 944}\n",
      "3 {'lives': 3, 'episode_frame_number': 948, 'frame_number': 948}\n",
      "3 {'lives': 3, 'episode_frame_number': 952, 'frame_number': 952}\n",
      "3 {'lives': 3, 'episode_frame_number': 956, 'frame_number': 956}\n",
      "3 {'lives': 3, 'episode_frame_number': 960, 'frame_number': 960}\n",
      "3 {'lives': 3, 'episode_frame_number': 964, 'frame_number': 964}\n",
      "3 {'lives': 3, 'episode_frame_number': 968, 'frame_number': 968}\n",
      "3 {'lives': 3, 'episode_frame_number': 972, 'frame_number': 972}\n",
      "3 {'lives': 3, 'episode_frame_number': 976, 'frame_number': 976}\n",
      "3 {'lives': 3, 'episode_frame_number': 980, 'frame_number': 980}\n",
      "3 {'lives': 3, 'episode_frame_number': 984, 'frame_number': 984}\n",
      "3 {'lives': 3, 'episode_frame_number': 988, 'frame_number': 988}\n",
      "3 {'lives': 3, 'episode_frame_number': 992, 'frame_number': 992}\n",
      "3 {'lives': 3, 'episode_frame_number': 996, 'frame_number': 996}\n",
      "3 {'lives': 3, 'episode_frame_number': 1000, 'frame_number': 1000}\n",
      "3 {'lives': 3, 'episode_frame_number': 1004, 'frame_number': 1004}\n",
      "3 {'lives': 3, 'episode_frame_number': 1008, 'frame_number': 1008}\n",
      "3 {'lives': 3, 'episode_frame_number': 1012, 'frame_number': 1012}\n",
      "3 {'lives': 3, 'episode_frame_number': 1016, 'frame_number': 1016}\n",
      "2 {'lives': 3, 'episode_frame_number': 1020, 'frame_number': 1020}\n",
      "3 {'lives': 3, 'episode_frame_number': 1024, 'frame_number': 1024}\n",
      "0 {'lives': 3, 'episode_frame_number': 1028, 'frame_number': 1028}\n",
      "3 {'lives': 3, 'episode_frame_number': 1032, 'frame_number': 1032}\n",
      "3 {'lives': 3, 'episode_frame_number': 1036, 'frame_number': 1036}\n",
      "3 {'lives': 3, 'episode_frame_number': 1040, 'frame_number': 1040}\n",
      "3 {'lives': 3, 'episode_frame_number': 1044, 'frame_number': 1044}\n",
      "3 {'lives': 3, 'episode_frame_number': 1048, 'frame_number': 1048}\n",
      "3 {'lives': 3, 'episode_frame_number': 1052, 'frame_number': 1052}\n",
      "3 {'lives': 3, 'episode_frame_number': 1056, 'frame_number': 1056}\n",
      "3 {'lives': 3, 'episode_frame_number': 1060, 'frame_number': 1060}\n",
      "3 {'lives': 3, 'episode_frame_number': 1064, 'frame_number': 1064}\n",
      "3 {'lives': 3, 'episode_frame_number': 1068, 'frame_number': 1068}\n",
      "3 {'lives': 3, 'episode_frame_number': 1072, 'frame_number': 1072}\n",
      "3 {'lives': 3, 'episode_frame_number': 1076, 'frame_number': 1076}\n",
      "3 {'lives': 3, 'episode_frame_number': 1080, 'frame_number': 1080}\n",
      "3 {'lives': 3, 'episode_frame_number': 1084, 'frame_number': 1084}\n",
      "3 {'lives': 3, 'episode_frame_number': 1088, 'frame_number': 1088}\n",
      "3 {'lives': 3, 'episode_frame_number': 1092, 'frame_number': 1092}\n",
      "3 {'lives': 3, 'episode_frame_number': 1096, 'frame_number': 1096}\n",
      "3 {'lives': 3, 'episode_frame_number': 1100, 'frame_number': 1100}\n",
      "3 {'lives': 3, 'episode_frame_number': 1104, 'frame_number': 1104}\n",
      "3 {'lives': 3, 'episode_frame_number': 1108, 'frame_number': 1108}\n",
      "3 {'lives': 3, 'episode_frame_number': 1112, 'frame_number': 1112}\n",
      "3 {'lives': 3, 'episode_frame_number': 1116, 'frame_number': 1116}\n",
      "2 {'lives': 3, 'episode_frame_number': 1120, 'frame_number': 1120}\n",
      "3 {'lives': 3, 'episode_frame_number': 1124, 'frame_number': 1124}\n",
      "3 {'lives': 3, 'episode_frame_number': 1128, 'frame_number': 1128}\n",
      "3 {'lives': 3, 'episode_frame_number': 1132, 'frame_number': 1132}\n",
      "3 {'lives': 3, 'episode_frame_number': 1136, 'frame_number': 1136}\n",
      "2 {'lives': 3, 'episode_frame_number': 1140, 'frame_number': 1140}\n",
      "3 {'lives': 3, 'episode_frame_number': 1144, 'frame_number': 1144}\n",
      "3 {'lives': 3, 'episode_frame_number': 1148, 'frame_number': 1148}\n",
      "3 {'lives': 3, 'episode_frame_number': 1152, 'frame_number': 1152}\n",
      "3 {'lives': 3, 'episode_frame_number': 1156, 'frame_number': 1156}\n",
      "0 {'lives': 3, 'episode_frame_number': 1160, 'frame_number': 1160}\n",
      "3 {'lives': 3, 'episode_frame_number': 1164, 'frame_number': 1164}\n",
      "1 {'lives': 3, 'episode_frame_number': 1168, 'frame_number': 1168}\n",
      "3 {'lives': 3, 'episode_frame_number': 1172, 'frame_number': 1172}\n",
      "3 {'lives': 3, 'episode_frame_number': 1176, 'frame_number': 1176}\n",
      "3 {'lives': 3, 'episode_frame_number': 1180, 'frame_number': 1180}\n",
      "0 {'lives': 3, 'episode_frame_number': 1184, 'frame_number': 1184}\n",
      "3 {'lives': 3, 'episode_frame_number': 1188, 'frame_number': 1188}\n",
      "3 {'lives': 3, 'episode_frame_number': 1192, 'frame_number': 1192}\n",
      "3 {'lives': 3, 'episode_frame_number': 1196, 'frame_number': 1196}\n",
      "3 {'lives': 3, 'episode_frame_number': 1200, 'frame_number': 1200}\n",
      "3 {'lives': 3, 'episode_frame_number': 1204, 'frame_number': 1204}\n",
      "3 {'lives': 3, 'episode_frame_number': 1208, 'frame_number': 1208}\n",
      "3 {'lives': 3, 'episode_frame_number': 1212, 'frame_number': 1212}\n",
      "3 {'lives': 3, 'episode_frame_number': 1216, 'frame_number': 1216}\n",
      "3 {'lives': 3, 'episode_frame_number': 1220, 'frame_number': 1220}\n",
      "3 {'lives': 3, 'episode_frame_number': 1224, 'frame_number': 1224}\n",
      "3 {'lives': 3, 'episode_frame_number': 1228, 'frame_number': 1228}\n",
      "3 {'lives': 3, 'episode_frame_number': 1232, 'frame_number': 1232}\n",
      "3 {'lives': 3, 'episode_frame_number': 1236, 'frame_number': 1236}\n",
      "3 {'lives': 3, 'episode_frame_number': 1240, 'frame_number': 1240}\n",
      "2 {'lives': 3, 'episode_frame_number': 1244, 'frame_number': 1244}\n",
      "3 {'lives': 3, 'episode_frame_number': 1248, 'frame_number': 1248}\n",
      "3 {'lives': 3, 'episode_frame_number': 1252, 'frame_number': 1252}\n",
      "3 {'lives': 3, 'episode_frame_number': 1256, 'frame_number': 1256}\n",
      "3 {'lives': 3, 'episode_frame_number': 1260, 'frame_number': 1260}\n",
      "3 {'lives': 2, 'episode_frame_number': 1264, 'frame_number': 1264}\n",
      "3 {'lives': 2, 'episode_frame_number': 1268, 'frame_number': 1268}\n",
      "0 {'lives': 2, 'episode_frame_number': 1272, 'frame_number': 1272}\n",
      "3 {'lives': 2, 'episode_frame_number': 1276, 'frame_number': 1276}\n",
      "3 {'lives': 2, 'episode_frame_number': 1280, 'frame_number': 1280}\n",
      "3 {'lives': 2, 'episode_frame_number': 1284, 'frame_number': 1284}\n",
      "3 {'lives': 2, 'episode_frame_number': 1288, 'frame_number': 1288}\n",
      "3 {'lives': 2, 'episode_frame_number': 1292, 'frame_number': 1292}\n",
      "3 {'lives': 2, 'episode_frame_number': 1296, 'frame_number': 1296}\n",
      "3 {'lives': 2, 'episode_frame_number': 1300, 'frame_number': 1300}\n",
      "3 {'lives': 2, 'episode_frame_number': 1304, 'frame_number': 1304}\n",
      "3 {'lives': 2, 'episode_frame_number': 1308, 'frame_number': 1308}\n",
      "3 {'lives': 2, 'episode_frame_number': 1312, 'frame_number': 1312}\n",
      "3 {'lives': 2, 'episode_frame_number': 1316, 'frame_number': 1316}\n",
      "3 {'lives': 2, 'episode_frame_number': 1320, 'frame_number': 1320}\n",
      "3 {'lives': 2, 'episode_frame_number': 1324, 'frame_number': 1324}\n",
      "3 {'lives': 2, 'episode_frame_number': 1328, 'frame_number': 1328}\n",
      "3 {'lives': 2, 'episode_frame_number': 1332, 'frame_number': 1332}\n",
      "3 {'lives': 2, 'episode_frame_number': 1336, 'frame_number': 1336}\n",
      "3 {'lives': 2, 'episode_frame_number': 1340, 'frame_number': 1340}\n",
      "3 {'lives': 2, 'episode_frame_number': 1344, 'frame_number': 1344}\n",
      "3 {'lives': 2, 'episode_frame_number': 1348, 'frame_number': 1348}\n",
      "3 {'lives': 2, 'episode_frame_number': 1352, 'frame_number': 1352}\n",
      "3 {'lives': 2, 'episode_frame_number': 1356, 'frame_number': 1356}\n",
      "3 {'lives': 2, 'episode_frame_number': 1360, 'frame_number': 1360}\n",
      "3 {'lives': 2, 'episode_frame_number': 1364, 'frame_number': 1364}\n",
      "3 {'lives': 2, 'episode_frame_number': 1368, 'frame_number': 1368}\n",
      "3 {'lives': 2, 'episode_frame_number': 1372, 'frame_number': 1372}\n",
      "2 {'lives': 2, 'episode_frame_number': 1376, 'frame_number': 1376}\n",
      "3 {'lives': 2, 'episode_frame_number': 1380, 'frame_number': 1380}\n",
      "3 {'lives': 2, 'episode_frame_number': 1384, 'frame_number': 1384}\n",
      "3 {'lives': 2, 'episode_frame_number': 1388, 'frame_number': 1388}\n",
      "1 {'lives': 2, 'episode_frame_number': 1392, 'frame_number': 1392}\n",
      "3 {'lives': 2, 'episode_frame_number': 1396, 'frame_number': 1396}\n",
      "3 {'lives': 2, 'episode_frame_number': 1400, 'frame_number': 1400}\n",
      "3 {'lives': 2, 'episode_frame_number': 1404, 'frame_number': 1404}\n",
      "3 {'lives': 2, 'episode_frame_number': 1408, 'frame_number': 1408}\n",
      "3 {'lives': 2, 'episode_frame_number': 1412, 'frame_number': 1412}\n",
      "3 {'lives': 2, 'episode_frame_number': 1416, 'frame_number': 1416}\n",
      "3 {'lives': 2, 'episode_frame_number': 1420, 'frame_number': 1420}\n",
      "3 {'lives': 2, 'episode_frame_number': 1424, 'frame_number': 1424}\n",
      "3 {'lives': 2, 'episode_frame_number': 1428, 'frame_number': 1428}\n",
      "3 {'lives': 2, 'episode_frame_number': 1432, 'frame_number': 1432}\n",
      "3 {'lives': 2, 'episode_frame_number': 1436, 'frame_number': 1436}\n",
      "0 {'lives': 2, 'episode_frame_number': 1440, 'frame_number': 1440}\n",
      "3 {'lives': 2, 'episode_frame_number': 1444, 'frame_number': 1444}\n",
      "3 {'lives': 2, 'episode_frame_number': 1448, 'frame_number': 1448}\n",
      "3 {'lives': 2, 'episode_frame_number': 1452, 'frame_number': 1452}\n",
      "3 {'lives': 2, 'episode_frame_number': 1456, 'frame_number': 1456}\n",
      "3 {'lives': 2, 'episode_frame_number': 1460, 'frame_number': 1460}\n",
      "3 {'lives': 2, 'episode_frame_number': 1464, 'frame_number': 1464}\n",
      "3 {'lives': 2, 'episode_frame_number': 1468, 'frame_number': 1468}\n",
      "3 {'lives': 2, 'episode_frame_number': 1472, 'frame_number': 1472}\n",
      "3 {'lives': 2, 'episode_frame_number': 1476, 'frame_number': 1476}\n",
      "3 {'lives': 2, 'episode_frame_number': 1480, 'frame_number': 1480}\n",
      "0 {'lives': 2, 'episode_frame_number': 1484, 'frame_number': 1484}\n",
      "3 {'lives': 2, 'episode_frame_number': 1488, 'frame_number': 1488}\n",
      "2 {'lives': 2, 'episode_frame_number': 1492, 'frame_number': 1492}\n",
      "3 {'lives': 2, 'episode_frame_number': 1496, 'frame_number': 1496}\n",
      "3 {'lives': 2, 'episode_frame_number': 1500, 'frame_number': 1500}\n",
      "3 {'lives': 2, 'episode_frame_number': 1504, 'frame_number': 1504}\n",
      "3 {'lives': 2, 'episode_frame_number': 1508, 'frame_number': 1508}\n",
      "3 {'lives': 2, 'episode_frame_number': 1512, 'frame_number': 1512}\n",
      "3 {'lives': 2, 'episode_frame_number': 1516, 'frame_number': 1516}\n",
      "0 {'lives': 2, 'episode_frame_number': 1520, 'frame_number': 1520}\n",
      "3 {'lives': 2, 'episode_frame_number': 1524, 'frame_number': 1524}\n",
      "3 {'lives': 2, 'episode_frame_number': 1528, 'frame_number': 1528}\n",
      "3 {'lives': 2, 'episode_frame_number': 1532, 'frame_number': 1532}\n",
      "1 {'lives': 2, 'episode_frame_number': 1536, 'frame_number': 1536}\n",
      "3 {'lives': 2, 'episode_frame_number': 1540, 'frame_number': 1540}\n",
      "3 {'lives': 2, 'episode_frame_number': 1544, 'frame_number': 1544}\n",
      "3 {'lives': 2, 'episode_frame_number': 1548, 'frame_number': 1548}\n",
      "3 {'lives': 2, 'episode_frame_number': 1552, 'frame_number': 1552}\n",
      "3 {'lives': 2, 'episode_frame_number': 1556, 'frame_number': 1556}\n",
      "3 {'lives': 2, 'episode_frame_number': 1560, 'frame_number': 1560}\n",
      "3 {'lives': 2, 'episode_frame_number': 1564, 'frame_number': 1564}\n",
      "3 {'lives': 2, 'episode_frame_number': 1568, 'frame_number': 1568}\n",
      "0 {'lives': 2, 'episode_frame_number': 1572, 'frame_number': 1572}\n",
      "3 {'lives': 2, 'episode_frame_number': 1576, 'frame_number': 1576}\n",
      "3 {'lives': 2, 'episode_frame_number': 1580, 'frame_number': 1580}\n",
      "3 {'lives': 2, 'episode_frame_number': 1584, 'frame_number': 1584}\n",
      "3 {'lives': 2, 'episode_frame_number': 1588, 'frame_number': 1588}\n",
      "3 {'lives': 2, 'episode_frame_number': 1592, 'frame_number': 1592}\n",
      "3 {'lives': 2, 'episode_frame_number': 1596, 'frame_number': 1596}\n",
      "3 {'lives': 2, 'episode_frame_number': 1600, 'frame_number': 1600}\n",
      "3 {'lives': 2, 'episode_frame_number': 1604, 'frame_number': 1604}\n",
      "0 {'lives': 2, 'episode_frame_number': 1608, 'frame_number': 1608}\n",
      "3 {'lives': 1, 'episode_frame_number': 1612, 'frame_number': 1612}\n",
      "3 {'lives': 1, 'episode_frame_number': 1616, 'frame_number': 1616}\n",
      "3 {'lives': 1, 'episode_frame_number': 1620, 'frame_number': 1620}\n",
      "3 {'lives': 1, 'episode_frame_number': 1624, 'frame_number': 1624}\n",
      "1 {'lives': 1, 'episode_frame_number': 1628, 'frame_number': 1628}\n",
      "3 {'lives': 1, 'episode_frame_number': 1632, 'frame_number': 1632}\n",
      "3 {'lives': 1, 'episode_frame_number': 1636, 'frame_number': 1636}\n",
      "3 {'lives': 1, 'episode_frame_number': 1640, 'frame_number': 1640}\n",
      "3 {'lives': 1, 'episode_frame_number': 1644, 'frame_number': 1644}\n",
      "3 {'lives': 1, 'episode_frame_number': 1648, 'frame_number': 1648}\n",
      "3 {'lives': 1, 'episode_frame_number': 1652, 'frame_number': 1652}\n",
      "3 {'lives': 1, 'episode_frame_number': 1656, 'frame_number': 1656}\n",
      "3 {'lives': 1, 'episode_frame_number': 1660, 'frame_number': 1660}\n",
      "3 {'lives': 1, 'episode_frame_number': 1664, 'frame_number': 1664}\n",
      "3 {'lives': 1, 'episode_frame_number': 1668, 'frame_number': 1668}\n",
      "3 {'lives': 1, 'episode_frame_number': 1672, 'frame_number': 1672}\n",
      "3 {'lives': 1, 'episode_frame_number': 1676, 'frame_number': 1676}\n",
      "3 {'lives': 1, 'episode_frame_number': 1680, 'frame_number': 1680}\n",
      "3 {'lives': 1, 'episode_frame_number': 1684, 'frame_number': 1684}\n",
      "3 {'lives': 1, 'episode_frame_number': 1688, 'frame_number': 1688}\n",
      "3 {'lives': 1, 'episode_frame_number': 1692, 'frame_number': 1692}\n",
      "1 {'lives': 1, 'episode_frame_number': 1696, 'frame_number': 1696}\n",
      "3 {'lives': 1, 'episode_frame_number': 1700, 'frame_number': 1700}\n",
      "3 {'lives': 1, 'episode_frame_number': 1704, 'frame_number': 1704}\n",
      "3 {'lives': 1, 'episode_frame_number': 1708, 'frame_number': 1708}\n",
      "3 {'lives': 1, 'episode_frame_number': 1712, 'frame_number': 1712}\n",
      "3 {'lives': 1, 'episode_frame_number': 1716, 'frame_number': 1716}\n",
      "3 {'lives': 1, 'episode_frame_number': 1720, 'frame_number': 1720}\n",
      "3 {'lives': 1, 'episode_frame_number': 1724, 'frame_number': 1724}\n",
      "3 {'lives': 1, 'episode_frame_number': 1728, 'frame_number': 1728}\n",
      "1 {'lives': 1, 'episode_frame_number': 1732, 'frame_number': 1732}\n",
      "3 {'lives': 1, 'episode_frame_number': 1736, 'frame_number': 1736}\n",
      "3 {'lives': 1, 'episode_frame_number': 1740, 'frame_number': 1740}\n",
      "3 {'lives': 1, 'episode_frame_number': 1744, 'frame_number': 1744}\n",
      "3 {'lives': 1, 'episode_frame_number': 1748, 'frame_number': 1748}\n",
      "3 {'lives': 1, 'episode_frame_number': 1752, 'frame_number': 1752}\n",
      "3 {'lives': 1, 'episode_frame_number': 1756, 'frame_number': 1756}\n",
      "3 {'lives': 1, 'episode_frame_number': 1760, 'frame_number': 1760}\n",
      "3 {'lives': 1, 'episode_frame_number': 1764, 'frame_number': 1764}\n",
      "3 {'lives': 1, 'episode_frame_number': 1768, 'frame_number': 1768}\n",
      "3 {'lives': 1, 'episode_frame_number': 1772, 'frame_number': 1772}\n",
      "3 {'lives': 1, 'episode_frame_number': 1776, 'frame_number': 1776}\n",
      "3 {'lives': 1, 'episode_frame_number': 1780, 'frame_number': 1780}\n",
      "3 {'lives': 1, 'episode_frame_number': 1784, 'frame_number': 1784}\n",
      "3 {'lives': 1, 'episode_frame_number': 1788, 'frame_number': 1788}\n",
      "3 {'lives': 1, 'episode_frame_number': 1792, 'frame_number': 1792}\n",
      "3 {'lives': 1, 'episode_frame_number': 1796, 'frame_number': 1796}\n",
      "3 {'lives': 1, 'episode_frame_number': 1800, 'frame_number': 1800}\n",
      "3 {'lives': 1, 'episode_frame_number': 1804, 'frame_number': 1804}\n",
      "1 {'lives': 1, 'episode_frame_number': 1808, 'frame_number': 1808}\n",
      "3 {'lives': 1, 'episode_frame_number': 1812, 'frame_number': 1812}\n",
      "3 {'lives': 1, 'episode_frame_number': 1816, 'frame_number': 1816}\n",
      "3 {'lives': 1, 'episode_frame_number': 1820, 'frame_number': 1820}\n",
      "3 {'lives': 1, 'episode_frame_number': 1824, 'frame_number': 1824}\n",
      "3 {'lives': 1, 'episode_frame_number': 1828, 'frame_number': 1828}\n",
      "3 {'lives': 1, 'episode_frame_number': 1832, 'frame_number': 1832}\n",
      "3 {'lives': 1, 'episode_frame_number': 1836, 'frame_number': 1836}\n",
      "3 {'lives': 1, 'episode_frame_number': 1840, 'frame_number': 1840}\n",
      "3 {'lives': 1, 'episode_frame_number': 1844, 'frame_number': 1844}\n",
      "3 {'lives': 1, 'episode_frame_number': 1848, 'frame_number': 1848}\n",
      "3 {'lives': 0, 'episode_frame_number': 1851, 'frame_number': 1851}\n"
     ]
    }
   ],
   "source": [
    "s, info = reset(env)\n",
    "s = torch.tensor(s)\n",
    "terminated = False\n",
    "while terminated == False:\n",
    "    a = dqn.select_next_action(s.permute(2, 0, 1).unsqueeze(0), 0.1)\n",
    "    s_prime, r, terminated, truncated, info = step(env, a)\n",
    "\n",
    "    s_prime = preprocess(s_prime)\n",
    "    s_prime = torch.cat([s, s_prime.unsqueeze(2)], 2)[:, :, -4:]\n",
    "    print(a, info)\n",
    "    s = s_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602edb90",
   "metadata": {
    "id": "602edb90",
    "outputId": "c0bccd79-ad9f-4c94-b944-8440658e7cc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.047"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(51 * 197) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f8044",
   "metadata": {
    "id": "9b9f8044",
    "outputId": "18c3694a-3b66-4b88-c3d7-c1a174a74017"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60244d69",
   "metadata": {
    "id": "60244d69"
   },
   "outputs": [],
   "source": [
    "y_hat, y = get_batch(dqn, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f030f44",
   "metadata": {
    "id": "0f030f44",
    "outputId": "d23ce108-2c0a-4363-e335-b8f01fa86f93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ee48f",
   "metadata": {
    "id": "751ee48f",
    "outputId": "d5187cad-cc51-4d9c-aeee-f5b5a150d199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772 µs ± 11.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "s_prime, r, terminated, truncated, info = step(env, a)\n",
    "s_prime = preprocess(s_prime)\n",
    "s_prime = torch.cat([s, s_prime.unsqueeze(2)], 2)[:, :, -4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b31313",
   "metadata": {
    "id": "50b31313",
    "outputId": "c49049a1-9015-4698-cf1f-81b50e9fc33c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.076"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22 * 458 /1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc5a83",
   "metadata": {
    "id": "a8bc5a83"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
