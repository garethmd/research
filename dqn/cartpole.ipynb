{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19e4e2e7-cfea-4164-bb47-d7a6fd1f4e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import wandb\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e64751f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "gamma = 0.99\n",
    "epsilon = 1\n",
    "lr=1e-4\n",
    "ENV_NAME =  \"CartPole-v1\"\n",
    "replay_memory_max_size = 10000\n",
    "number_of_episodes = 500\n",
    "sync_every_n_steps = 500\n",
    "max_episode_length = 500\n",
    "epsilon_annealing_steps = 1000\n",
    "loss_fn = nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ed29b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0001,\n",
       " 'architecture': 'DQN',\n",
       " 'environment': 'CartPole-v1',\n",
       " 'epsilon': 1,\n",
       " 'gamma': 0.99,\n",
       " 'bs': 16,\n",
       " 'replay_memory_max_size': 10000,\n",
       " 'number_of_episodes': 500,\n",
       " 'max_episode_length': 500,\n",
       " 'sync_every_n_steps': 500,\n",
       " 'epsilon_annealing_steps': 1000,\n",
       " 'loss': 'SmoothL1Loss()'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"learning_rate\": lr,\n",
    "    \"architecture\": \"DQN\",\n",
    "    \"environment\": ENV_NAME,\n",
    "    \"epsilon\": epsilon,\n",
    "    \"gamma\":gamma,\n",
    "    \"bs\":bs,\n",
    "    \"replay_memory_max_size\":replay_memory_max_size,\n",
    "    \"number_of_episodes\":number_of_episodes,\n",
    "    \"max_episode_length\":max_episode_length,\n",
    "    \"sync_every_n_steps\": sync_every_n_steps,\n",
    "    \"epsilon_annealing_steps\":epsilon_annealing_steps,\n",
    "    \"loss\": str(loss_fn),\n",
    "    }\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65556ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgarethmd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/garethdavies/Development/workspaces/rl/dqn/wandb/run-20240119_212336-2bnqv62z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/garethmd/cartpole/runs/2bnqv62z' target=\"_blank\">dauntless-sea-9</a></strong> to <a href='https://wandb.ai/garethmd/cartpole' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/garethmd/cartpole' target=\"_blank\">https://wandb.ai/garethmd/cartpole</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/garethmd/cartpole/runs/2bnqv62z' target=\"_blank\">https://wandb.ai/garethmd/cartpole/runs/2bnqv62z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/garethmd/cartpole/runs/2bnqv62z?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x126382b60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"cartpole\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb7660d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchEnv:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.n_observations = self.env.observation_space.shape[0]\n",
    "        self.n_actions = self.env.action_space.n\n",
    "        \n",
    "    def step(self, a):\n",
    "        s, r, terminated, truncated, info = self.env.step(a)\n",
    "        return torch.tensor(s), torch.tensor(r), terminated, truncated, info\n",
    "    \n",
    "    def reset(self, *args, **kwargs):\n",
    "        s, info = self.env.reset(*args, **kwargs)\n",
    "        return torch.tensor(s), info\n",
    "    \n",
    "    def close(self):\n",
    "        return self.env.close()\n",
    "    \n",
    "env = TorchEnv(gym.make(ENV_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcf3cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden_dim: int, n_actions: int) -> None:\n",
    "        super(DQN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, n_actions)\n",
    "        )\n",
    "        self.n_actions = n_actions\n",
    "    \n",
    "    def forward(self, s: torch.tensor) -> torch.tensor:\n",
    "        return self.net(s)\n",
    "    \n",
    "    def select_next_action(self, s: torch.tensor, epsilon: float) -> int:\n",
    "        with torch.no_grad(): # no need to track gradients selecting next action\n",
    "            use_greedy = np.random.binomial(1, 1-epsilon)\n",
    "            if use_greedy:\n",
    "                a = self(s).argmax().item()\n",
    "            else:\n",
    "                a = np.random.randint(self.n_actions)\n",
    "            return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e0479c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplay:\n",
    "    def __init__(self, maxlen: int) -> None:\n",
    "        self.deque = deque(maxlen=maxlen)\n",
    "        \n",
    "    def append(self, x: tuple) -> None:\n",
    "        self.deque.append(x)\n",
    "        \n",
    "    def sample(self, bs: int) -> list:\n",
    "        return random.sample(self.deque, min(len(self), bs))\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.deque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8f8ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(replay_memory: ExperienceReplay, env: TorchEnv) -> None:\n",
    "    while len(replay_memory)<replay_memory_max_size:\n",
    "        s, info = env.reset()\n",
    "        terminated=False\n",
    "        while terminated == False:\n",
    "            a = np.random.randint(env.n_actions)\n",
    "            s_prime, r, terminated, *_ = env.step(a)\n",
    "            replay_memory.append((s, a, r, s_prime, terminated))\n",
    "            s = s_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "691940ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pole_collate(batch: list) -> tuple:\n",
    "    s_j, a_j, r_j, s_prime_j, terminated_j = list(zip(*batch))\n",
    "    return torch.stack(s_j), torch.tensor(a_j), torch.tensor(r_j), torch.stack(s_prime_j), (~torch.tensor(terminated_j)).float()\n",
    "\n",
    "def get_batch(self, batch: list, target_net:DQN=None, collate_fn:callable=pole_collate) -> tuple:\n",
    "    if target_net is None:\n",
    "        target_net = self\n",
    "\n",
    "    s, a, r, s_prime, not_terminated = collate_fn(batch)\n",
    "    y_hat = self(s).gather(1, a.unsqueeze(1)).squeeze() # gather the values at the indices given by the actions a \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        next_values = target_net(s_prime).max(dim=1).values.clone().detach()\n",
    "        y_j = r.detach().clone() + gamma * next_values * not_terminated # if terminated then not_terminated is set to zero (y_j = r)\n",
    "    return y_hat, y_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb819e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory = ExperienceReplay(replay_memory_max_size)\n",
    "fill(replay_memory, env) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db4bde47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQN(in_dim=env.n_observations, hidden_dim=64, n_actions=env.n_actions)\n",
    "target_net = DQN(in_dim=env.n_observations, hidden_dim=64, n_actions=env.n_actions)\n",
    "target_net.load_state_dict(dqn.state_dict())\n",
    "optimizer = torch.optim.Adam(dqn.parameters(),  lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290043ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "\n",
    "# Magic\n",
    "#wandb.watch(dqn, log_freq=100)\n",
    "\n",
    "for i in range(number_of_episodes):\n",
    "    terminated = False\n",
    "    s, info = env.reset(seed=42)\n",
    "    episode_loss, episode_reward, episode_length, k  = 0, 0, 0, 0\n",
    "    while terminated == False and k < max_episode_length:\n",
    "        a = dqn.select_next_action(s, epsilon)\n",
    "        s_prime, r, terminated, *_ = env.step(a)\n",
    "        \n",
    "        replay_memory.append((s, a, r, s_prime, terminated))\n",
    "        batch = replay_memory.sample(bs)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_hat, y = get_batch_efficient(dqn, batch, target_net=target_net)\n",
    "        \n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(dqn.parameters(), 100)\n",
    "        optimizer.step()\n",
    "        if epsilon > 0.05 :\n",
    "            epsilon -= (1 / epsilon_annealing_steps)\n",
    "        \n",
    "        if step % sync_every_n_steps == 0:\n",
    "            target_net.load_state_dict(dqn.state_dict())\n",
    "            \n",
    "        s = s_prime\n",
    "        \n",
    "        episode_loss += loss.item()\n",
    "        episode_reward += r.item()\n",
    "        episode_length += 1\n",
    "        k += 1\n",
    "        step += 1\n",
    "            \n",
    "    if i % 100 == 0:\n",
    "        wandb.log({\"eposide\":i,\n",
    "                    \"episode_loss\": episode_loss, \n",
    "                   \"reward\": episode_reward,\n",
    "                   \"step\":step\n",
    "                  })\n",
    "        print({\"eposide\":i,\n",
    "                    \"episode_loss\": episode_loss / k, \n",
    "                   \"reward\": episode_reward,\n",
    "                   \"step\":step\n",
    "                  })\n",
    "model_path = 'cartpole.pth'\n",
    "torch.save(dqn.state_dict(), model_path)\n",
    "wandb.log_model(name=f\"cartpole-{wandb.run.id}\", path=model_path)\n",
    "env.close()\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
